{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "from icecream import ic"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchvision import transforms as transform_lib\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "from dataset.cityscapes import Cityscapes\n",
    "from dataset.cityscapes import CityscapesDataModule\n",
    "from dataset.woodscape import WoodScapeDataset\n",
    "from dataset.woodscape import WoodScapeDataModule\n",
    "from dataset import WoodScapeSoilingDataset\n",
    "from dataset import WoodScapeSoilingDataModule"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "from utils.display_images import denormalize_img\n",
    "from utils import show_dataset_image, show_dataset_mask\n",
    "from utils import show_prediction_images, show_prediction_uncertainty_images"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "from deeplab_v3p import DeepLabV3PlusModule\n",
    "from dropblock import DropBlock2D"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "from ls_ood_detect.uncertainty_estimation import Hook\n",
    "from ls_ood_detect.uncertainty_estimation import deeplabv3p_get_ls_mcd_samples\n",
    "from ls_ood_detect.uncertainty_estimation import get_dl_h_z\n",
    "from ls_ood_detect.ood_detection_dataset import build_ood_detection_ds\n",
    "from ls_ood_detect.dimensionality_reduction import plot_samples_pacmap\n",
    "from ls_ood_detect.detectors import KDEClassifier\n",
    "from ls_ood_detect.metrics import get_ood_detector_results, plot_roc_ood_detector"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OoD/Anomaly Detection Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for using the package:\n",
    "\n",
    "1. Load you Dataloader Pytorch-Lightning Module\n",
    "2. Load your trained DNN PyTorch-Lightning Module\n",
    "3. Add Hook to DNN Module for MC samples extraction\n",
    "4. Get Monte-Carlo (MC) samples for In-Distribution (InD) samples dataloader, and Out-of-Distribution (OoD) samples dataloader\n",
    "5. Get Entropy from InD and OoD MC samples\n",
    "6. Build OoD Detection dataset (with InD and OoD samples)\n",
    "7. Build OoD data-driven Detector (classifier)\n",
    "8. Show OoD performance results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woodscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "ws_dataset_path = './Data/DATASETS/WoodScape/'\n",
    "batch_size = 1\n",
    "\n",
    "cmap = {0: [0, 0, 0],  # \"void\"\n",
    "        1: [128, 64, 128],  # \"road\",\n",
    "        2: [69, 76, 11],  # \"lanemarks\",\n",
    "        3: [0, 255, 0],  # \"curb\",\n",
    "        4: [220, 20, 60],  # \"person\",\n",
    "        5: [255, 0, 0],  # \"rider\",\n",
    "        6: [0, 0, 142],  # \"vehicles\",\n",
    "        7: [119, 11, 32],  # \"bicycle\",\n",
    "        8: [0, 0, 230],  # \"motorcycle\",\n",
    "        9: [220, 220, 0]  # \"traffic_sign\",\n",
    "        }\n",
    "\n",
    "# same values as in VainF Repository! - Probably not the best Values for Woodscapes!\n",
    "ws_dlv3p_norm_mean = [0.485, 0.456, 0.406]\n",
    "ws_dlv3p_norm_std = [0.229, 0.224, 0.225]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape img_size (483, 640)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "ws_dm_normal_dlv3p = WoodScapeDataModule(dataset_dir=ws_dataset_path,\n",
    "                                         img_size=(483, 640),\n",
    "                                         batch_size=batch_size,\n",
    "                                         default_transforms=True,\n",
    "                                         label_colours=cmap,\n",
    "                                         norm_mean=ws_dlv3p_norm_mean,\n",
    "                                         norm_std=ws_dlv3p_norm_std,\n",
    "                                         seed=9290,\n",
    "                                         drop_last=True)\n",
    "ws_dm_normal_dlv3p.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape img_size (256, 512)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "ws_dm_normal_dlv3p_256_512 = WoodScapeDataModule(dataset_dir=ws_dataset_path,\n",
    "                                         img_size=(256, 512),\n",
    "                                         batch_size=batch_size,\n",
    "                                         default_transforms=True,\n",
    "                                         label_colours=cmap,\n",
    "                                         norm_mean=ws_dlv3p_norm_mean,\n",
    "                                         norm_std=ws_dlv3p_norm_std,\n",
    "                                         seed=9290,\n",
    "                                         drop_last=True)\n",
    "ws_dm_normal_dlv3p_256_512.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape-Anomalies img_size (483, 640)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "ws_dm_anomal_dlv3p = WoodScapeDataModule(dataset_dir=ws_dataset_path,\n",
    "                                         img_size=(483, 640),\n",
    "                                         batch_size=batch_size,\n",
    "                                         default_transforms=True,\n",
    "                                         label_colours=cmap,\n",
    "                                         norm_mean=ws_dlv3p_norm_mean,\n",
    "                                         norm_std=ws_dlv3p_norm_std,\n",
    "                                         seed=9290,\n",
    "                                         drop_last=True)\n",
    "ws_dm_anomal_dlv3p.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woodscape dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "ws_dlv3p_train_loader = ws_dm_normal_dlv3p.train_dataloader()\n",
    "ws_dlv3p_valid_loader = ws_dm_normal_dlv3p.val_dataloader()\n",
    "ws_dlv3p_test_loader = ws_dm_normal_dlv3p.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "ws_dlv3p_anomaly_valid_loader = ws_dm_anomal_dlv3p.anomaly_val_dataloader()\n",
    "ws_dlv3p_anomaly_test_loader = ws_dm_anomal_dlv3p.anomaly_test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "ws_256512_dlv3p_valid_loader = ws_dm_normal_dlv3p_256_512.val_dataloader()\n",
    "ws_256512_dlv3p_test_loader = ws_dm_normal_dlv3p_256_512.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "ic(len(ws_dlv3p_train_loader));\n",
    "ic(len(ws_dlv3p_valid_loader));\n",
    "ic(len(ws_dlv3p_test_loader));\n",
    "ic(len(ws_dlv3p_anomaly_valid_loader));\n",
    "ic(len(ws_dlv3p_anomaly_test_loader));\n",
    "ic(len(ws_256512_dlv3p_valid_loader));\n",
    "ic(len(ws_256512_dlv3p_test_loader));"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cityscapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "dataset_path = './Data/DATASETS/CityScapes'\n",
    "batch_size = 1"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cityscapes img_size (256, 512)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "cs_dm_normal_dlv3p = CityscapesDataModule(data_dir=dataset_path,\n",
    "                                          batch_size=batch_size,\n",
    "                                          target_type='semantic',\n",
    "                                          img_size=(256, 512),\n",
    "                                          num_workers=10,\n",
    "                                          drop_last=True,\n",
    "                                          default_transforms=True, # Here this should be True!\n",
    "                                          default_img_mask_transforms=False) # And here this should be False!\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cityscapes img_size (483, 640)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "\n",
    "cs_483640_dm_dlv3p = CityscapesDataModule(data_dir=dataset_path,\n",
    "                                          batch_size=batch_size,\n",
    "                                          target_type='semantic',\n",
    "                                          img_size=(483, 640),\n",
    "                                          num_workers=10,\n",
    "                                          drop_last=True,\n",
    "                                          default_transforms=True, # Here this should be True!\n",
    "                                          default_img_mask_transforms=False) # And here this should be False!        "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cityscapes-Anomalies img_size (256, 512)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "cs_dm_anomal_dlv3p = CityscapesDataModule(data_dir=dataset_path,\n",
    "                                          batch_size=batch_size,\n",
    "                                          target_type='semantic',\n",
    "                                          img_size=(256, 512),\n",
    "                                          num_workers=10,\n",
    "                                          drop_last=True,\n",
    "                                          default_transforms=False, # Here this should be False!\n",
    "                                          default_img_mask_transforms=True) # And here this should be True! (Enable Anomalies)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "cs_dlv3p_train_loader = cs_dm_normal_dlv3p.train_dataloader()\n",
    "cs_dlv3p_valid_loader = cs_dm_normal_dlv3p.val_dataloader()\n",
    "cs_dlv3p_test_loader = cs_dm_normal_dlv3p.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "cs_dlv3p_anomaly_valid_loader = cs_dm_anomal_dlv3p.anomaly_val_dataloader()\n",
    "cs_dlv3p_anomaly_test_loader = cs_dm_anomal_dlv3p.anomaly_test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "cs_483640_dlv3p_valid_loader = cs_483640_dm_dlv3p.val_dataloader()\n",
    "cs_483640_dlv3p_test_loader = cs_483640_dm_dlv3p.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "ic(len(cs_dlv3p_train_loader));\n",
    "ic(len(cs_dlv3p_valid_loader));\n",
    "ic(len(cs_dlv3p_test_loader));\n",
    "ic(len(cs_dlv3p_anomaly_valid_loader));\n",
    "ic(len(cs_dlv3p_anomaly_test_loader));\n",
    "ic(len(cs_483640_dlv3p_valid_loader));\n",
    "ic(len(cs_483640_dlv3p_test_loader));"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woodscape-Soiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape Soling OoD DeeplabV3+ (483, 640)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "woodscape_soil_483640_dm = WoodScapeSoilingDataModule(dataset_dir=\"./Data/DATASETS/WoodScape/soiling_dataset/\",\n",
    "                                                      img_size=(483, 640),\n",
    "                                                      batch_size=1,\n",
    "                                                      default_transforms=True,\n",
    "                                                      seed=9290)\n",
    "woodscape_soil_483640_dm.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape Soling OoD DeeplabV3+ (256, 512)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "woodscape_soil_256512_dm = WoodScapeSoilingDataModule(dataset_dir=\"./Data/DATASETS/WoodScape/soiling_dataset/\",\n",
    "                                                      img_size=(256, 512),\n",
    "                                                      batch_size=1,\n",
    "                                                      default_transforms=True,\n",
    "                                                      seed=9290)\n",
    "woodscape_soil_256512_dm.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "ws_soiling_483640_valid_loader = woodscape_soil_483640_dm.val_dataloader()\n",
    "ws_soiling_483640_test_loader = woodscape_soil_483640_dm.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "ws_soiling_256512_valid_loader = woodscape_soil_256512_dm.val_dataloader()\n",
    "ws_soiling_256512_test_loader = woodscape_soil_256512_dm.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "ic(len(ws_soiling_483640_valid_loader));\n",
    "ic(len(ws_soiling_483640_test_loader));\n",
    "ic(len(ws_soiling_256512_valid_loader));\n",
    "ic(len(ws_soiling_256512_test_loader));"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplabv3+ Woodscape Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "ws_dlv3p_path = \"./lightning_logs/version_66126/checkpoints/last.ckpt\"\n",
    "ws_dlv3p_model = DeepLabV3PlusModule.load_from_checkpoint(checkpoint_path=ws_dlv3p_path)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "ic(ws_dlv3p_model.pred_loss_type);\n",
    "ic(ws_dlv3p_model.n_class);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "source": [
    "ws_dlv3p_model.eval();"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Hook Deeplabv3+ Woodscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "ic(ws_dlv3p_model.deeplab_v3plus_model.drop_block1);\n",
    "ic(ws_dlv3p_model.deeplab_v3plus_model.drop_block1.block_size);\n",
    "ic(ws_dlv3p_model.deeplab_v3plus_model.drop_block1.drop_prob);\n",
    "ic(ws_dlv3p_model.deeplab_v3plus_model.drop_block1.training);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "source": [
    "ws_dlv3p_hook_dropblock2d_layer = Hook(ws_dlv3p_model.deeplab_v3plus_model.drop_block1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Monte Carlo Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "# Monte Carlo Dropout - Enable Dropout @ Test Time!\n",
    "def deeplabv3p_apply_dropout(m):\n",
    "    if type(m) == torch.nn.Dropout or type(m) == DropBlock2D:\n",
    "        m.train()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "source": [
    "mc_samples = 16"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "ws_dlv3p_model.deeplab_v3plus_model.to(device);\n",
    "ws_dlv3p_model.deeplab_v3plus_model.eval(); \n",
    "ws_dlv3p_model.deeplab_v3plus_model.apply(deeplabv3p_apply_dropout); # enable dropout"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "source": [
    "ic(ws_dlv3p_model.deeplab_v3plus_model.drop_block1.drop_prob);\n",
    "ic(ws_dlv3p_model.deeplab_v3plus_model.drop_block1.training);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "ws_dlv3p_ws_normal_train_16mc_samples = deeplabv3p_get_ls_mcd_samples(ws_dlv3p_model,\n",
    "                                                                      ws_dlv3p_train_loader,\n",
    "                                                                      mc_samples,\n",
    "                                                                      ws_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "source": [
    "ws_dlv3p_ws_normal_valid_16mc_samples = deeplabv3p_get_ls_mcd_samples(ws_dlv3p_model,\n",
    "                                                                      ws_dlv3p_valid_loader,\n",
    "                                                                      mc_samples,\n",
    "                                                                      ws_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "ws_dlv3p_ws_normal_test_16mc_samples = deeplabv3p_get_ls_mcd_samples(ws_dlv3p_model,\n",
    "                                                                     ws_dlv3p_test_loader,\n",
    "                                                                     mc_samples,\n",
    "                                                                     ws_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "source": [
    "ws_dlv3p_ws_anomal_valid_16mc_samples = deeplabv3p_get_ls_mcd_samples(ws_dlv3p_model,\n",
    "                                                                      ws_dlv3p_anomaly_valid_loader,\n",
    "                                                                      mc_samples,\n",
    "                                                                      ws_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "ws_dlv3p_ws_anomal_test_16mc_samples = deeplabv3p_get_ls_mcd_samples(ws_dlv3p_model,\n",
    "                                                                     ws_dlv3p_anomaly_test_loader,\n",
    "                                                                     mc_samples,\n",
    "                                                                     ws_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "source": [
    "ws_dlv3p_cs_483640_valid_16mc_samples = deeplabv3p_get_ls_mcd_samples(ws_dlv3p_model,\n",
    "                                                                      cs_483640_dlv3p_valid_loader,\n",
    "                                                                      mc_samples,\n",
    "                                                                      ws_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "ws_dlv3p_cs_483640_test_16mc_samples = deeplabv3p_get_ls_mcd_samples(ws_dlv3p_model,\n",
    "                                                                     cs_483640_dlv3p_test_loader,\n",
    "                                                                     mc_samples,\n",
    "                                                                     ws_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "source": [
    "ws_dlv3p_ws_soiling_483640_valid_16mc_samples = deeplabv3p_get_ls_mcd_samples(ws_dlv3p_model,\n",
    "                                                                              ws_soiling_483640_valid_loader,\n",
    "                                                                              mc_samples,\n",
    "                                                                              ws_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "ws_dlv3p_ws_soiling_483640_test_16mc_samples = deeplabv3p_get_ls_mcd_samples(ws_dlv3p_model,\n",
    "                                                                             ws_soiling_483640_test_loader,\n",
    "                                                                             mc_samples,\n",
    "                                                                             ws_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "source": [
    "torch.save(ws_dlv3p_ws_normal_train_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_normal_train_16mc_samples.pt')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "source": [
    "torch.save(ws_dlv3p_ws_normal_valid_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_normal_valid_16mc_samples.pt')\n",
    "torch.save(ws_dlv3p_ws_normal_test_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_normal_test_16mc_samples.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "source": [
    "torch.save(ws_dlv3p_ws_anomal_valid_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_anomal_valid_16mc_samples.pt')\n",
    "torch.save(ws_dlv3p_ws_anomal_test_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_anomal_test_16mc_samples.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "source": [
    "torch.save(ws_dlv3p_cs_483640_valid_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_cs_483640_valid_16mc_samples.pt')\n",
    "torch.save(ws_dlv3p_cs_483640_test_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_cs_483640_test_16mc_samples.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "source": [
    "torch.save(ws_dlv3p_ws_soiling_483640_valid_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_soiling_483640_valid_16mc_samples.pt')\n",
    "torch.save(ws_dlv3p_ws_soiling_483640_test_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_soiling_483640_test_16mc_samples.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "source": [
    "ws_dlv3p_ws_normal_train_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_normal_train_16mc_samples.pt')\n",
    "ws_dlv3p_ws_normal_valid_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_normal_valid_16mc_samples.pt')\n",
    "ws_dlv3p_ws_normal_test_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_normal_test_16mc_samples.pt')\n",
    "\n",
    "ws_dlv3p_ws_anomal_valid_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_anomal_valid_16mc_samples.pt')\n",
    "ws_dlv3p_ws_anomal_test_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_anomal_test_16mc_samples.pt')\n",
    "\n",
    "ws_dlv3p_cs_483640_valid_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_cs_483640_valid_16mc_samples.pt')\n",
    "ws_dlv3p_cs_483640_test_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_cs_483640_test_16mc_samples.pt')\n",
    "\n",
    "ws_dlv3p_ws_soiling_483640_valid_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_soiling_483640_valid_16mc_samples.pt')\n",
    "ws_dlv3p_ws_soiling_483640_test_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/mc_samples/ws_dlv3p_ws_soiling_483640_test_16mc_samples.pt')"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "source": [
    "_, ws_dlv3p_h_z_ws_normal_train_samples_np = get_dl_h_z(ws_dlv3p_ws_normal_train_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "_, ws_dlv3p_h_z_ws_normal_valid_samples_np = get_dl_h_z(ws_dlv3p_ws_normal_valid_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "source": [
    "_, ws_dlv3p_h_z_ws_normal_test_samples_np = get_dl_h_z(ws_dlv3p_ws_normal_test_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "source": [
    "_, ws_dlv3p_h_z_ws_anomal_valid_samples_np = get_dl_h_z(ws_dlv3p_ws_anomal_valid_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "source": [
    "_, ws_dlv3p_h_z_ws_anomal_test_samples_np = get_dl_h_z(ws_dlv3p_ws_anomal_test_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "source": [
    "_, ws_dlv3p_h_z_cs_483640_valid_samples_np = get_dl_h_z(ws_dlv3p_cs_483640_valid_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "source": [
    "_, ws_dlv3p_h_z_cs_483640_test_samples_np = get_dl_h_z(ws_dlv3p_cs_483640_test_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "source": [
    "_, ws_dlv3p_h_z_ws_soil_483640_valid_samples_np = get_dl_h_z(ws_dlv3p_ws_soiling_483640_valid_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "source": [
    "_, ws_dlv3p_h_z_ws_soil_483640_test_samples_np = get_dl_h_z(ws_dlv3p_ws_soiling_483640_test_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "source": [
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/entropy/ws_dlv3p_h_z_ws_normal_train_samples_np',\n",
    "        ws_dlv3p_h_z_ws_normal_train_samples_np)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/entropy/ws_dlv3p_h_z_ws_normal_valid_samples_np',\n",
    "        ws_dlv3p_h_z_ws_normal_valid_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/entropy/ws_dlv3p_h_z_ws_normal_test_samples_np',\n",
    "        ws_dlv3p_h_z_ws_normal_test_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/entropy/ws_dlv3p_h_z_ws_anomal_valid_samples_np',\n",
    "        ws_dlv3p_h_z_ws_anomal_valid_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/entropy/ws_dlv3p_h_z_ws_anomal_test_samples_np',\n",
    "        ws_dlv3p_h_z_ws_anomal_test_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/entropy/ws_dlv3p_h_z_cs_483640_valid_samples_np',\n",
    "        ws_dlv3p_h_z_cs_483640_valid_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/entropy/ws_dlv3p_h_z_cs_483640_test_samples_np',\n",
    "        ws_dlv3p_h_z_cs_483640_test_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/entropy/ws_dlv3p_h_z_ws_soil_483640_valid_samples_np',\n",
    "        ws_dlv3p_h_z_ws_soil_483640_valid_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p/embeddings/woodscape/entropy/ws_dlv3p_h_z_ws_soil_483640_test_samples_np',\n",
    "        ws_dlv3p_h_z_ws_soil_483640_test_samples_np)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Semantic_Segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

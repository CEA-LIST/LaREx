{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "from collections import namedtuple\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "from icecream import ic"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchvision import transforms as transform_lib\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "from dataset.cityscapes import Cityscapes\n",
    "from dataset.cityscapes import CityscapesDataModule\n",
    "from dataset.woodscape import WoodScapeDataset\n",
    "from dataset.woodscape import WoodScapeDataModule\n",
    "from dataset import WoodScapeSoilingDataset\n",
    "from dataset import WoodScapeSoilingDataModule"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "from utils.display_images import denormalize_img\n",
    "from utils import show_dataset_image, show_dataset_mask\n",
    "from utils import show_prediction_images, show_prediction_uncertainty_images"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "from deeplab_v3p import DeepLabV3PlusModule\n",
    "from dropblock import DropBlock2D"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "from ls_ood_detect.uncertainty_estimation import Hook\n",
    "from ls_ood_detect.uncertainty_estimation import deeplabv3p_get_ls_mcd_samples\n",
    "from ls_ood_detect.uncertainty_estimation import get_latent_represent_mcd_samples\n",
    "from ls_ood_detect.uncertainty_estimation import get_dl_h_z\n",
    "from ls_ood_detect.ood_detection_dataset import build_ood_detection_ds\n",
    "from ls_ood_detect.dimensionality_reduction import plot_samples_pacmap\n",
    "from ls_ood_detect.detectors import KDEClassifier, DetectorKDE\n",
    "from ls_ood_detect.score import get_hz_scores\n",
    "from ls_ood_detect.metrics import get_hz_detector_results\n",
    "from ls_ood_detect.metrics import get_ood_detector_results\n",
    "from ls_ood_detect.metrics import plot_roc_ood_detector\n",
    "from ls_ood_detect.metrics import plot_auprc_ood_detector\n",
    "from ls_ood_detect.dimensionality_reduction import plot_samples_pacmap\n",
    "from ls_ood_detect.dimensionality_reduction import apply_pca_ds_split\n",
    "from ls_ood_detect.dimensionality_reduction import apply_pca_transform"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "cs_dataset_path = \"./Data/DATASETS/CityScapes\"\n",
    "ws_data_path = \"./Data/DATASETS/WoodScape/\"\n",
    "ws_soil_data_path = \"./Data/DATASETS/WoodScape/soiling_dataset/\""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "exp_path = \"./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/\""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet Classification Model Number & checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "exp_model_name = \"deeplabv3p-woodscape/\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "ws_dlv3p_path = exp_path + exp_model_name + \"models/version_66126/checkpoints/last.ckpt\"\n",
    "ws_dlv3p_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline models path:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "baseline_methods_path = \"OoD_detection_baselines/\""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection Baselines Samples Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "baselines_samples_path = \"OoD_detection_baselines/\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "predicted_uncertainty_path = exp_path + exp_model_name + baseline_methods_path + \"predicted_uncertainty/\"\n",
    "predicted_uncertainty_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "msp_score_path = exp_path + exp_model_name + baseline_methods_path + \"msp_score/\"\n",
    "msp_score_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "energy_score_path = exp_path + exp_model_name + baseline_methods_path + \"energy_score/\"\n",
    "energy_score_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "m_dist_score_path = exp_path + exp_model_name + baseline_methods_path + \"mahalanobis_dist_score/\"\n",
    "m_dist_score_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "m_dist_penultimate_layer_score_path = exp_path + exp_model_name + baseline_methods_path + \"mahalanobis_dist_penultimate_layer_score/\"\n",
    "m_dist_penultimate_layer_score_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "knn_dist_score_path = exp_path + exp_model_name + baseline_methods_path + \"knn_dist_score/\"\n",
    "knn_dist_score_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "knn_dist_penultimate_layer_score_path = exp_path + exp_model_name + baseline_methods_path + \"knn_dist_penultimate_layer_score/\"\n",
    "knn_dist_penultimate_layer_score_path"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cityscapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "batch_size = 1"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cityscapes img_size (483, 640)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "\n",
    "cs_483640_dm_dlv3p = CityscapesDataModule(data_dir=cs_dataset_path,\n",
    "                                          batch_size=batch_size,\n",
    "                                          target_type='semantic',\n",
    "                                          img_size=(483, 640),\n",
    "                                          num_workers=10,\n",
    "                                          drop_last=True,\n",
    "                                          default_transforms=True, # Here this should be True!\n",
    "                                          default_img_mask_transforms=False) # And here this should be False!        "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "cs_483640_dlv3p_valid_loader = cs_483640_dm_dlv3p.val_dataloader()\n",
    "cs_483640_dlv3p_test_loader = cs_483640_dm_dlv3p.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "ic(len(cs_483640_dlv3p_valid_loader));\n",
    "ic(len(cs_483640_dlv3p_test_loader));"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woodscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "batch_size = 1\n",
    "\n",
    "cmap = {0: [0, 0, 0],  # \"void\"\n",
    "        1: [128, 64, 128],  # \"road\",\n",
    "        2: [69, 76, 11],  # \"lanemarks\",\n",
    "        3: [0, 255, 0],  # \"curb\",\n",
    "        4: [220, 20, 60],  # \"person\",\n",
    "        5: [255, 0, 0],  # \"rider\",\n",
    "        6: [0, 0, 142],  # \"vehicles\",\n",
    "        7: [119, 11, 32],  # \"bicycle\",\n",
    "        8: [0, 0, 230],  # \"motorcycle\",\n",
    "        9: [220, 220, 0]  # \"traffic_sign\",\n",
    "        }\n",
    "\n",
    "# same values as in VainF Repository! - Probably not the best Values for Woodscapes!\n",
    "ws_dlv3p_norm_mean = [0.485, 0.456, 0.406]\n",
    "ws_dlv3p_norm_std = [0.229, 0.224, 0.225]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape img_size (483, 640)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "ws_dm_normal_dlv3p = WoodScapeDataModule(dataset_dir=ws_data_path,\n",
    "                                         img_size=(483, 640),\n",
    "                                         batch_size=batch_size,\n",
    "                                         default_transforms=True,\n",
    "                                         label_colours=cmap,\n",
    "                                         norm_mean=ws_dlv3p_norm_mean,\n",
    "                                         norm_std=ws_dlv3p_norm_std,\n",
    "                                         seed=9290,\n",
    "                                         drop_last=True)\n",
    "ws_dm_normal_dlv3p.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape img_size (256, 512)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "# ws_dm_normal_dlv3p_256_512 = WoodScapeDataModule(dataset_dir=ws_data_path,\n",
    "#                                          img_size=(256, 512),\n",
    "#                                          batch_size=batch_size,\n",
    "#                                          default_transforms=True,\n",
    "#                                          label_colours=cmap,\n",
    "#                                          norm_mean=ws_dlv3p_norm_mean,\n",
    "#                                          norm_std=ws_dlv3p_norm_std,\n",
    "#                                          seed=9290,\n",
    "#                                          drop_last=True)\n",
    "# ws_dm_normal_dlv3p_256_512.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape-Anomalies img_size (483, 640)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "ws_dm_anomal_dlv3p = WoodScapeDataModule(dataset_dir=ws_data_path,\n",
    "                                         img_size=(483, 640),\n",
    "                                         batch_size=batch_size,\n",
    "                                         default_transforms=True,\n",
    "                                         label_colours=cmap,\n",
    "                                         norm_mean=ws_dlv3p_norm_mean,\n",
    "                                         norm_std=ws_dlv3p_norm_std,\n",
    "                                         seed=9290,\n",
    "                                         drop_last=True)\n",
    "ws_dm_anomal_dlv3p.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woodscape dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "ws_dlv3p_train_loader = ws_dm_normal_dlv3p.train_dataloader()\n",
    "ws_dlv3p_valid_loader = ws_dm_normal_dlv3p.val_dataloader()\n",
    "ws_dlv3p_test_loader = ws_dm_normal_dlv3p.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "source": [
    "ws_dlv3p_anomaly_valid_loader = ws_dm_anomal_dlv3p.anomaly_val_dataloader()\n",
    "ws_dlv3p_anomaly_test_loader = ws_dm_anomal_dlv3p.anomaly_test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "# ws_256512_dlv3p_valid_loader = ws_dm_normal_dlv3p_256_512.val_dataloader()\n",
    "# ws_256512_dlv3p_test_loader = ws_dm_normal_dlv3p_256_512.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "ic(len(ws_dlv3p_train_loader));\n",
    "ic(len(ws_dlv3p_valid_loader));\n",
    "ic(len(ws_dlv3p_test_loader));\n",
    "ic(len(ws_dlv3p_anomaly_valid_loader));\n",
    "ic(len(ws_dlv3p_anomaly_test_loader));\n",
    "# ic(len(ws_256512_dlv3p_valid_loader));\n",
    "# ic(len(ws_256512_dlv3p_test_loader));"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woodscape-Soiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape Soling OoD DeeplabV3+ (483, 640)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "source": [
    "woodscape_soil_483640_dm = WoodScapeSoilingDataModule(dataset_dir=ws_soil_data_path,\n",
    "                                                      img_size=(483, 640),\n",
    "                                                      batch_size=1,\n",
    "                                                      default_transforms=True,\n",
    "                                                      seed=9290)\n",
    "woodscape_soil_483640_dm.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape Soling OoD DeeplabV3+ (256, 512)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "# woodscape_soil_256512_dm = WoodScapeSoilingDataModule(dataset_dir=ws_soil_data_path,\n",
    "#                                                       img_size=(256, 512),\n",
    "#                                                       batch_size=1,\n",
    "#                                                       default_transforms=True,\n",
    "#                                                       seed=9290)\n",
    "# woodscape_soil_256512_dm.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "source": [
    "ws_soiling_483640_valid_loader = woodscape_soil_483640_dm.val_dataloader()\n",
    "ws_soiling_483640_test_loader = woodscape_soil_483640_dm.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "source": [
    "# ws_soiling_256512_valid_loader = woodscape_soil_256512_dm.val_dataloader()\n",
    "# ws_soiling_256512_test_loader = woodscape_soil_256512_dm.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "source": [
    "ic(len(ws_soiling_483640_valid_loader));\n",
    "ic(len(ws_soiling_483640_test_loader));\n",
    "# ic(len(ws_soiling_256512_valid_loader));\n",
    "# ic(len(ws_soiling_256512_test_loader));"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplabv3+ Woodscape Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "source": [
    "ws_dlv3p_model = DeepLabV3PlusModule.load_from_checkpoint(checkpoint_path=ws_dlv3p_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "source": [
    "ws_dlv3p_model;"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "ic(ws_dlv3p_model.pred_loss_type);\n",
    "ic(ws_dlv3p_model.n_class);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "source": [
    "ws_dlv3p_model.eval();"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Distribution Shift Detection Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "ic(len(ws_dlv3p_train_loader));\n",
    "ic(len(ws_dlv3p_valid_loader));\n",
    "ic(len(ws_dlv3p_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(ws_dlv3p_anomaly_valid_loader));\n",
    "ic(len(ws_dlv3p_anomaly_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(cs_483640_dlv3p_valid_loader));\n",
    "ic(len(cs_483640_dlv3p_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(ws_soiling_483640_valid_loader));\n",
    "ic(len(ws_soiling_483640_test_loader));"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mahalanobis Distance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "source": [
    "class Hook:\n",
    "    \"\"\"\n",
    "    Hook class that returns the input and output of a layer during forward/backward pass\n",
    "    \"\"\"\n",
    "    def __init__(self, module: torch.nn.Module, backward: bool = False):\n",
    "        \"\"\"\n",
    "        Hook Class constructor\n",
    "        :param module: Layer block from Neural Network Module\n",
    "        :type module: torch.nn.Module\n",
    "        :param backward: backward-poss hook\n",
    "        :type backward: bool\n",
    "        \"\"\"\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        if not backward:\n",
    "            self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        else:\n",
    "            self.hook = module.register_backward_hook(self.hook_fn)\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "\n",
    "    def close(self):\n",
    "        self.hook.remove()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "source": [
    "from sklearn.covariance import EmpiricalCovariance\n",
    "\n",
    "class MDSPostprocessor:\n",
    "    def __init__(self,\n",
    "                 num_classes: int = 43,\n",
    "                 setup_flag: bool = False,\n",
    "                 get_2d_rep_mean: bool = False):\n",
    "        # self.config = config\n",
    "        # self.num_classes = num_classes_dict[self.config.dataset.name]\n",
    "        self.num_classes = num_classes\n",
    "        self.setup_flag = setup_flag\n",
    "        self.get_2d_rep_mean = get_2d_rep_mean\n",
    "        self.feats_mean = None\n",
    "        self.precision = None\n",
    "\n",
    "    def setup(self,\n",
    "              dnn_model: nn.Module,\n",
    "              ind_dataloader,\n",
    "              layer_hook):\n",
    "        \n",
    "        if not self.setup_flag:\n",
    "            # estimate mean and variance from training set\n",
    "            print('\\n Estimating mean and variance from training set...')\n",
    "            all_feats = []\n",
    "            # all_labels = []\n",
    "            # all_preds = []\n",
    "            centered_data = []\n",
    "            # get features/representations:\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            dnn_model.to(device)\n",
    "            # get features:\n",
    "            with torch.no_grad():\n",
    "                for i, (image, label) in enumerate(ind_dataloader):\n",
    "                    image = image.to(device)\n",
    "                    # label = label.to(device)\n",
    "                    pred_logits = dnn_model(image)\n",
    "                    # latent_rep = torch.flatten(layer_hook.output, 1)  # latent representation sample\n",
    "                    latent_rep = layer_hook.output  # latent representation sample\n",
    "                \n",
    "                    if self.get_2d_rep_mean:\n",
    "                        # Get image HxW mean:\n",
    "                        latent_rep = torch.mean(latent_rep, dim=2, keepdim=True)\n",
    "                        latent_rep = torch.mean(latent_rep, dim=3, keepdim=True)\n",
    "                        # Remove useless dimensions:\n",
    "                        latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "                        latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "\n",
    "                    all_feats.append(latent_rep.cpu())\n",
    "                    # all_labels.append(deepcopy(label))\n",
    "                    # all_preds.append(pred_logits.argmax(1).cpu())\n",
    "                    \n",
    "            all_feats = torch.cat(all_feats)\n",
    "            # all_labels = torch.cat(all_labels)\n",
    "            # all_preds = torch.cat(all_preds)\n",
    "            \n",
    "            self.feats_mean = all_feats.mean(0)\n",
    "            centered_data.append(all_feats - self.feats_mean.view(1, -1))\n",
    "            self.centered_data = torch.cat(centered_data)\n",
    "              \n",
    "            group_lasso = EmpiricalCovariance(assume_centered=False)\n",
    "            group_lasso.fit(self.centered_data.cpu().numpy().astype(np.float32))\n",
    "            \n",
    "            self.precision = torch.from_numpy(group_lasso.precision_).float()\n",
    "            self.setup_flag = True\n",
    "            \n",
    "            # we need to use:\n",
    "            # self.feats_mean & self.precision\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def postprocess(self,\n",
    "                    dnn_model: nn.Module,\n",
    "                    dataloader: DataLoader,\n",
    "                    layer_hook):\n",
    "        \n",
    "        # all_preds = []\n",
    "        all_conf_score = []\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        dnn_model.to(device)\n",
    "        \n",
    "        for i, (image, label) in enumerate(dataloader):\n",
    "            image = image.to(device)\n",
    "            pred_logits = dnn_model(image)\n",
    "            # latent_rep = layer_hook.output\n",
    "            latent_rep = layer_hook.output  # latent representation sample\n",
    "        \n",
    "            if self.get_2d_rep_mean:\n",
    "                # Get image HxW mean:\n",
    "                latent_rep = torch.mean(latent_rep, dim=2, keepdim=True)\n",
    "                latent_rep = torch.mean(latent_rep, dim=3, keepdim=True)\n",
    "                # Remove useless dimensions:\n",
    "                latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "                latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "\n",
    "            diff_t = latent_rep.cpu() - self.feats_mean.view(1, -1)\n",
    "            # diff_t = latent_rep.cpu() - self.feats_mean\n",
    "            conf_score = -torch.matmul(torch.matmul(diff_t, self.precision),\n",
    "                                  diff_t.t()).diag()\n",
    "            \n",
    "            all_conf_score.append(conf_score)\n",
    "            \n",
    "        all_conf_score_t = torch.cat(all_conf_score)\n",
    "        \n",
    "        return all_conf_score_t"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "source": [
    "ic(len(ws_dlv3p_train_loader));\n",
    "ic(len(ws_dlv3p_valid_loader));\n",
    "ic(len(ws_dlv3p_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(ws_dlv3p_anomaly_valid_loader));\n",
    "ic(len(ws_dlv3p_anomaly_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(cs_483640_dlv3p_valid_loader));\n",
    "ic(len(cs_483640_dlv3p_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(ws_soiling_483640_valid_loader));\n",
    "ic(len(ws_soiling_483640_test_loader));"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "source": [
    "ws_dlv3p_model.deeplab_v3plus_model.drop_block1.training"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Model Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "source": [
    "ws_dlv3p_hook_dropblock2d_layer = Hook(ws_dlv3p_model.deeplab_v3plus_model.drop_block1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis Distance Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "source": [
    "m_dist_ws_dlv3p = MDSPostprocessor(num_classes=1, setup_flag=False, get_2d_rep_mean=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "source": [
    "m_dist_ws_dlv3p.setup(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                      ws_dlv3p_train_loader,\n",
    "                      layer_hook=ws_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "source": [
    "ic(m_dist_ws_dlv3p.feats_mean.shape);\n",
    "ic(m_dist_ws_dlv3p.precision.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis Distance Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "source": [
    "ind_ws_valid_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                        ws_dlv3p_valid_loader,\n",
    "                                                        ws_dlv3p_hook_dropblock2d_layer)\n",
    "ic(ind_ws_valid_m_dist_score.shape);\n",
    "\n",
    "ind_ws_test_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                       ws_dlv3p_test_loader,\n",
    "                                                       ws_dlv3p_hook_dropblock2d_layer)\n",
    "ic(ind_ws_test_m_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "source": [
    "ood_ws_anomal_valid_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                               ws_dlv3p_anomaly_valid_loader,\n",
    "                                                               ws_dlv3p_hook_dropblock2d_layer)\n",
    "ic(ood_ws_anomal_valid_m_dist_score.shape);\n",
    "\n",
    "\n",
    "ood_ws_anomal_test_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                              ws_dlv3p_anomaly_test_loader,\n",
    "                                                              ws_dlv3p_hook_dropblock2d_layer)\n",
    "ic(ood_ws_anomal_test_m_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "source": [
    "ood_cs_valid_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                        cs_483640_dlv3p_valid_loader,\n",
    "                                                        ws_dlv3p_hook_dropblock2d_layer)\n",
    "ic(ood_cs_valid_m_dist_score.shape);\n",
    "\n",
    "ood_cs_test_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                       cs_483640_dlv3p_test_loader,\n",
    "                                                       ws_dlv3p_hook_dropblock2d_layer)\n",
    "ic(ood_cs_test_m_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "source": [
    "ood_ws_soil_valid_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                             ws_soiling_483640_valid_loader,\n",
    "                                                             ws_dlv3p_hook_dropblock2d_layer)\n",
    "ic(ood_ws_soil_valid_m_dist_score.shape);\n",
    "\n",
    "ood_ws_soil_test_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                            ws_soiling_483640_test_loader,\n",
    "                                                            ws_dlv3p_hook_dropblock2d_layer)\n",
    "ic(ood_ws_soil_test_m_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "source": [
    "ind_ws_m_dist_score = np.concatenate((ind_ws_valid_m_dist_score, ind_ws_test_m_dist_score))\n",
    "ood_ws_anomal_m_dist_score = np.concatenate((ood_ws_anomal_valid_m_dist_score, ood_ws_anomal_test_m_dist_score))\n",
    "ood_cs_m_dist_score = np.concatenate((ood_cs_valid_m_dist_score, ood_cs_test_m_dist_score))\n",
    "ood_ws_soil_m_dist_score = np.concatenate((ood_ws_soil_valid_m_dist_score, ood_ws_soil_test_m_dist_score))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "m_dist_score_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "source": [
    "np.save(m_dist_score_path + 'ind_ws_m_dist_score',\n",
    "        ind_ws_m_dist_score)\n",
    "\n",
    "np.save(m_dist_score_path + 'ood_ws_anomal_m_dist_score',\n",
    "        ood_ws_anomal_m_dist_score)\n",
    "\n",
    "np.save(m_dist_score_path + 'ood_cs_m_dist_score',\n",
    "        ood_cs_m_dist_score)\n",
    "\n",
    "np.save(m_dist_score_path + 'ood_ws_soil_m_dist_score',\n",
    "        ood_ws_soil_m_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "source": [
    "ic(ind_ws_m_dist_score.shape);\n",
    "ic(ood_ws_anomal_m_dist_score.shape);\n",
    "ic(ood_cs_m_dist_score.shape);\n",
    "ic(ood_ws_soil_m_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "source": [
    "df_m_dist_scores_ws = pd.DataFrame(ind_ws_m_dist_score, columns=[\"Mahalanobis Distance score\"])\n",
    "df_m_dist_scores_ws_anomal = pd.DataFrame(ood_ws_anomal_m_dist_score, columns=[\"Mahalanobis Distance score\"])\n",
    "df_m_dist_scores_cs = pd.DataFrame(ood_cs_m_dist_score, columns=[\"Mahalanobis Distance score\"])\n",
    "df_m_dist_scores_ws_soil = pd.DataFrame(ood_ws_soil_m_dist_score, columns=[\"Mahalanobis Distance score\"])\n",
    "\n",
    "df_m_dist_scores_ws.insert(0, \"Dataset\", \"\")\n",
    "df_m_dist_scores_ws.loc[:, \"Dataset\"] = \"woodscape\"\n",
    "\n",
    "df_m_dist_scores_ws_anomal.insert(0, \"Dataset\", \"\")\n",
    "df_m_dist_scores_ws_anomal.loc[:, \"Dataset\"] = \"woodscape-anomalies\"\n",
    "\n",
    "df_m_dist_scores_cs.insert(0, \"Dataset\", \"\")\n",
    "df_m_dist_scores_cs.loc[:, \"Dataset\"] = \"cityscapes\"\n",
    "\n",
    "df_m_dist_scores_ws_soil.insert(0, \"Dataset\", \"\")\n",
    "df_m_dist_scores_ws_soil.loc[:, \"Dataset\"] = \"woodscape-soiling\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "source": [
    "df_m_dist_scores = pd.concat([df_m_dist_scores_ws,\n",
    "                              df_m_dist_scores_ws_anomal,\n",
    "                              df_m_dist_scores_cs,\n",
    "                              df_m_dist_scores_ws_soil]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_m_dist_scores, x=\"Mahalanobis Distance score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "source": [
    "df_m_dist_scores = pd.concat([df_m_dist_scores_ws,\n",
    "                              df_m_dist_scores_ws_anomal]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_m_dist_scores, x=\"Mahalanobis Distance score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "source": [
    "df_m_dist_scores = pd.concat([df_m_dist_scores_ws,\n",
    "                              df_m_dist_scores_ws_soil]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_m_dist_scores, x=\"Mahalanobis Distance score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes vs Cityscapes-Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use negative uncertainty scores for to align with the convention that positive (in-distribution) samples have higher scores (see plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "source": [
    "print(\"Test InD shape\", ind_ws_m_dist_score.shape);\n",
    "print(\"Test OoD shape\", ood_ws_anomal_m_dist_score.shape);\n",
    "\n",
    "results_m_dist_cs_anomaly = get_hz_detector_results(detect_exp_name=\"Mahalanobis Distance score: woodscape vs. woodscape-anomalies\",\n",
    "                                                    ind_samples_scores=ind_ws_m_dist_score,\n",
    "                                                    ood_samples_scores=ood_ws_anomal_m_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes vs Woodscapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use negative uncertainty scores for to align with the convention that positive (in-distribution) samples have higher scores (see plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "source": [
    "print(\"Test InD shape\", ind_ws_m_dist_score.shape);\n",
    "print(\"Test OoD shape\", ood_cs_m_dist_score.shape);\n",
    "\n",
    "results_m_dist_ws = get_hz_detector_results(detect_exp_name=\"Mahalanobis Distance score: woodscape vs. cityscapes\",\n",
    "                                            ind_samples_scores=ind_ws_m_dist_score,\n",
    "                                            ood_samples_scores=ood_cs_m_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes vs Woodscapes-Soiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use negative uncertainty scores for to align with the convention that positive (in-distribution) samples have higher scores (see plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "source": [
    "print(\"Test InD shape\", ind_ws_m_dist_score.shape);\n",
    "print(\"Test OoD shape\", ood_ws_soil_m_dist_score.shape);\n",
    "\n",
    "results_m_dist_ws_soil = get_hz_detector_results(detect_exp_name=\"Mahalanobis Distance score: woodscape vs. woodscape-soiling\",\n",
    "                                                    ind_samples_scores=ind_ws_m_dist_score,\n",
    "                                                    ood_samples_scores=ood_ws_soil_m_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mahalanobis Distance score penultimate layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "source": [
    "class Hook:\n",
    "    \"\"\"\n",
    "    Hook class that returns the input and output of a layer during forward/backward pass\n",
    "    \"\"\"\n",
    "    def __init__(self, module: torch.nn.Module, backward: bool = False):\n",
    "        \"\"\"\n",
    "        Hook Class constructor\n",
    "        :param module: Layer block from Neural Network Module\n",
    "        :type module: torch.nn.Module\n",
    "        :param backward: backward-poss hook\n",
    "        :type backward: bool\n",
    "        \"\"\"\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        if not backward:\n",
    "            self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        else:\n",
    "            self.hook = module.register_backward_hook(self.hook_fn)\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "\n",
    "    def close(self):\n",
    "        self.hook.remove()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "source": [
    "from sklearn.covariance import EmpiricalCovariance\n",
    "\n",
    "class MDSPostprocessor:\n",
    "    def __init__(self,\n",
    "                 num_classes: int = 43,\n",
    "                 setup_flag: bool = False,\n",
    "                 get_2d_rep_mean: bool = False):\n",
    "        # self.config = config\n",
    "        # self.num_classes = num_classes_dict[self.config.dataset.name]\n",
    "        self.num_classes = num_classes\n",
    "        self.setup_flag = setup_flag\n",
    "        self.get_2d_rep_mean = get_2d_rep_mean\n",
    "        self.feats_mean = None\n",
    "        self.precision = None\n",
    "\n",
    "    def setup(self,\n",
    "              dnn_model: nn.Module,\n",
    "              ind_dataloader,\n",
    "              layer_hook):\n",
    "        \n",
    "        if not self.setup_flag:\n",
    "            # estimate mean and variance from training set\n",
    "            print('\\n Estimating mean and variance from training set...')\n",
    "            all_feats = []\n",
    "            # all_labels = []\n",
    "            # all_preds = []\n",
    "            centered_data = []\n",
    "            # get features/representations:\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            dnn_model.to(device)\n",
    "            # get features:\n",
    "            with torch.no_grad():\n",
    "                for i, (image, label) in enumerate(ind_dataloader):\n",
    "                    image = image.to(device)\n",
    "                    # label = label.to(device)\n",
    "                    pred_logits = dnn_model(image)\n",
    "                    # latent_rep = torch.flatten(layer_hook.output, 1)  # latent representation sample\n",
    "                    latent_rep = layer_hook.output  # latent representation sample\n",
    "                \n",
    "                    if self.get_2d_rep_mean:\n",
    "                        # Get image HxW mean:\n",
    "                        latent_rep = torch.mean(latent_rep, dim=2, keepdim=True)\n",
    "                        latent_rep = torch.mean(latent_rep, dim=3, keepdim=True)\n",
    "                        # Remove useless dimensions:\n",
    "                        latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "                        latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "\n",
    "                    all_feats.append(latent_rep.cpu())\n",
    "                    # all_labels.append(deepcopy(label))\n",
    "                    # all_preds.append(pred_logits.argmax(1).cpu())\n",
    "                    \n",
    "            all_feats = torch.cat(all_feats)\n",
    "            # all_labels = torch.cat(all_labels)\n",
    "            # all_preds = torch.cat(all_preds)\n",
    "            \n",
    "            self.feats_mean = all_feats.mean(0)\n",
    "            centered_data.append(all_feats - self.feats_mean.view(1, -1))\n",
    "            self.centered_data = torch.cat(centered_data)\n",
    "              \n",
    "            group_lasso = EmpiricalCovariance(assume_centered=False)\n",
    "            group_lasso.fit(self.centered_data.cpu().numpy().astype(np.float32))\n",
    "            \n",
    "            self.precision = torch.from_numpy(group_lasso.precision_).float()\n",
    "            self.setup_flag = True\n",
    "            \n",
    "            # we need to use:\n",
    "            # self.feats_mean & self.precision\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def postprocess(self,\n",
    "                    dnn_model: nn.Module,\n",
    "                    dataloader: DataLoader,\n",
    "                    layer_hook):\n",
    "        \n",
    "        # all_preds = []\n",
    "        all_conf_score = []\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        dnn_model.to(device)\n",
    "        \n",
    "        for i, (image, label) in enumerate(dataloader):\n",
    "            image = image.to(device)\n",
    "            pred_logits = dnn_model(image)\n",
    "            # latent_rep = layer_hook.output\n",
    "            latent_rep = layer_hook.output  # latent representation sample\n",
    "        \n",
    "            if self.get_2d_rep_mean:\n",
    "                # Get image HxW mean:\n",
    "                latent_rep = torch.mean(latent_rep, dim=2, keepdim=True)\n",
    "                latent_rep = torch.mean(latent_rep, dim=3, keepdim=True)\n",
    "                # Remove useless dimensions:\n",
    "                latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "                latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "\n",
    "            diff_t = latent_rep.cpu() - self.feats_mean.view(1, -1)\n",
    "            # diff_t = latent_rep.cpu() - self.feats_mean\n",
    "            conf_score = -torch.matmul(torch.matmul(diff_t, self.precision),\n",
    "                                  diff_t.t()).diag()\n",
    "            \n",
    "            all_conf_score.append(conf_score)\n",
    "            \n",
    "        all_conf_score_t = torch.cat(all_conf_score)\n",
    "        \n",
    "        return all_conf_score_t"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "source": [
    "ic(len(ws_dlv3p_train_loader));\n",
    "ic(len(ws_dlv3p_valid_loader));\n",
    "ic(len(ws_dlv3p_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(ws_dlv3p_anomaly_valid_loader));\n",
    "ic(len(ws_dlv3p_anomaly_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(cs_483640_dlv3p_valid_loader));\n",
    "ic(len(cs_483640_dlv3p_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(ws_soiling_483640_valid_loader));\n",
    "ic(len(ws_soiling_483640_test_loader));"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ad Model Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "source": [
    "ws_dlv3p_model;"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "source": [
    "ws_dlv3p_model.deeplab_v3plus_model.classifier.classifier"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "source": [
    "ws_dlv3p_hook_penultimate_layer = Hook(ws_dlv3p_model.deeplab_v3plus_model.classifier.classifier[2])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis Distance Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "source": [
    "m_dist_ws_dlv3p = MDSPostprocessor(num_classes=1, setup_flag=False, get_2d_rep_mean=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "source": [
    "m_dist_ws_dlv3p.setup(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                      ws_dlv3p_train_loader,\n",
    "                      layer_hook=ws_dlv3p_hook_penultimate_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "source": [
    "ic(m_dist_ws_dlv3p.feats_mean.shape);\n",
    "ic(m_dist_ws_dlv3p.precision.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis Distance Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "source": [
    "ind_ws_valid_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                        ws_dlv3p_valid_loader,\n",
    "                                                        ws_dlv3p_hook_penultimate_layer)\n",
    "ic(ind_ws_valid_m_dist_score.shape);\n",
    "\n",
    "ind_ws_test_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                       ws_dlv3p_test_loader,\n",
    "                                                       ws_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "\n",
    "ic(ind_ws_test_m_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "source": [
    "ood_ws_anomal_valid_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                               ws_dlv3p_anomaly_valid_loader,\n",
    "                                                               ws_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "\n",
    "ood_ws_anomal_test_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                              ws_dlv3p_anomaly_test_loader,\n",
    "                                                              ws_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "ic(ood_ws_anomal_valid_m_dist_score.shape);\n",
    "ic(ood_ws_anomal_test_m_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "source": [
    "ood_cs_valid_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                        cs_483640_dlv3p_valid_loader,\n",
    "                                                        ws_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "\n",
    "ood_cs_test_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                       cs_483640_dlv3p_test_loader,\n",
    "                                                       ws_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "ic(ood_cs_valid_m_dist_score.shape);\n",
    "ic(ood_cs_test_m_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "source": [
    "ood_ws_soil_valid_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                             ws_soiling_483640_valid_loader,\n",
    "                                                             ws_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "\n",
    "ood_ws_soil_test_m_dist_score = m_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                            ws_soiling_483640_test_loader,\n",
    "                                                            ws_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "ic(ood_ws_soil_valid_m_dist_score.shape);\n",
    "ic(ood_ws_soil_test_m_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "source": [
    "ind_ws_m_dist_score = np.concatenate((ind_ws_valid_m_dist_score, ind_ws_test_m_dist_score))\n",
    "ood_ws_anomal_m_dist_score = np.concatenate((ood_ws_anomal_valid_m_dist_score, ood_ws_anomal_test_m_dist_score))\n",
    "ood_cs_m_dist_score = np.concatenate((ood_cs_valid_m_dist_score, ood_cs_test_m_dist_score))\n",
    "ood_ws_soil_m_dist_score = np.concatenate((ood_ws_soil_valid_m_dist_score, ood_ws_soil_test_m_dist_score))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "m_dist_penultimate_layer_score_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "source": [
    "np.save(m_dist_penultimate_layer_score_path + 'ind_ws_m_dist_score',\n",
    "        ind_ws_m_dist_score)\n",
    "\n",
    "np.save(m_dist_penultimate_layer_score_path + 'ood_ws_anomal_m_dist_score',\n",
    "        ood_ws_anomal_m_dist_score)\n",
    "\n",
    "np.save(m_dist_penultimate_layer_score_path + 'ood_cs_m_dist_score',\n",
    "        ood_cs_m_dist_score)\n",
    "\n",
    "np.save(m_dist_penultimate_layer_score_path + 'ood_ws_soil_m_dist_score',\n",
    "        ood_ws_soil_m_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "source": [
    "ic(ind_ws_m_dist_score.shape);\n",
    "ic(ood_ws_anomal_m_dist_score.shape);\n",
    "ic(ood_cs_m_dist_score.shape);\n",
    "ic(ood_ws_soil_m_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "source": [
    "df_m_dist_scores_ws = pd.DataFrame(ind_ws_m_dist_score, columns=[\"Mahalanobis Distance score\"])\n",
    "df_m_dist_scores_ws_anomal = pd.DataFrame(ood_ws_anomal_m_dist_score, columns=[\"Mahalanobis Distance score\"])\n",
    "df_m_dist_scores_cs = pd.DataFrame(ood_cs_m_dist_score, columns=[\"Mahalanobis Distance score\"])\n",
    "df_m_dist_scores_ws_soil = pd.DataFrame(ood_ws_soil_m_dist_score, columns=[\"Mahalanobis Distance score\"])\n",
    "\n",
    "df_m_dist_scores_ws.insert(0, \"Dataset\", \"\")\n",
    "df_m_dist_scores_ws.loc[:, \"Dataset\"] = \"woodscape\"\n",
    "\n",
    "df_m_dist_scores_ws_anomal.insert(0, \"Dataset\", \"\")\n",
    "df_m_dist_scores_ws_anomal.loc[:, \"Dataset\"] = \"woodscape-anomalies\"\n",
    "\n",
    "df_m_dist_scores_cs.insert(0, \"Dataset\", \"\")\n",
    "df_m_dist_scores_cs.loc[:, \"Dataset\"] = \"cityscapes\"\n",
    "\n",
    "df_m_dist_scores_ws_soil.insert(0, \"Dataset\", \"\")\n",
    "df_m_dist_scores_ws_soil.loc[:, \"Dataset\"] = \"woodscape-soiling\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "source": [
    "df_m_dist_scores = pd.concat([df_m_dist_scores_ws,\n",
    "                              df_m_dist_scores_ws_anomal]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_m_dist_scores, x=\"Mahalanobis Distance score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "source": [
    "df_m_dist_scores = pd.concat([df_m_dist_scores_ws,\n",
    "                              df_m_dist_scores_ws_soil]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_m_dist_scores, x=\"Mahalanobis Distance score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes vs Cityscapes-Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use negative uncertainty scores for to align with the convention that positive (in-distribution) samples have higher scores (see plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "source": [
    "print(\"Test InD shape\", ind_ws_m_dist_score.shape);\n",
    "print(\"Test OoD shape\", ood_ws_anomal_m_dist_score.shape);\n",
    "\n",
    "results_m_dist_cs_anomaly = get_hz_detector_results(detect_exp_name=\"Mahalanobis Distance score: woodscape vs. woodscape-anomaly\",\n",
    "                                                    ind_samples_scores=ind_ws_m_dist_score,\n",
    "                                                    ood_samples_scores=ood_ws_anomal_m_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes vs Woodscapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use negative uncertainty scores for to align with the convention that positive (in-distribution) samples have higher scores (see plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "source": [
    "print(\"Test InD shape\", ind_ws_m_dist_score.shape);\n",
    "print(\"Test OoD shape\", ood_cs_m_dist_score.shape);\n",
    "\n",
    "results_m_dist_ws = get_hz_detector_results(detect_exp_name=\"Mahalanobis Distance score: woodscape vs. cityscapes\",\n",
    "                                            ind_samples_scores=ind_ws_m_dist_score,\n",
    "                                            ood_samples_scores=ood_cs_m_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes vs Woodscapes-Soiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use negative uncertainty scores for to align with the convention that positive (in-distribution) samples have higher scores (see plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "source": [
    "print(\"Test InD shape\", ind_ws_m_dist_score.shape);\n",
    "print(\"Test OoD shape\", ood_ws_soil_m_dist_score.shape);\n",
    "\n",
    "results_m_dist_ws_soil = get_hz_detector_results(detect_exp_name=\"Mahalanobis Distance score: woodscape vs. woodscape-soiling\",\n",
    "                                                    ind_samples_scores=ind_ws_m_dist_score,\n",
    "                                                    ood_samples_scores=ood_ws_soil_m_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Distance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "source": [
    "import faiss"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "source": [
    "class Hook:\n",
    "    \"\"\"\n",
    "    Hook class that returns the input and output of a layer during forward/backward pass\n",
    "    \"\"\"\n",
    "    def __init__(self, module: torch.nn.Module, backward: bool = False):\n",
    "        \"\"\"\n",
    "        Hook Class constructor\n",
    "        :param module: Layer block from Neural Network Module\n",
    "        :type module: torch.nn.Module\n",
    "        :param backward: backward-poss hook\n",
    "        :type backward: bool\n",
    "        \"\"\"\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        if not backward:\n",
    "            self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        else:\n",
    "            self.hook = module.register_backward_hook(self.hook_fn)\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "\n",
    "    def close(self):\n",
    "        self.hook.remove()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "source": [
    "normalizer = lambda x: x / (np.linalg.norm(x, ord=2, axis=-1, keepdims=True) + 1e-10)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "source": [
    "class KNNPostprocessor:\n",
    "    def __init__(self,\n",
    "                 K: int = 50,\n",
    "                 setup_flag: bool = False,\n",
    "                 get_2d_rep_mean: bool = False):\n",
    "        self.K = K\n",
    "        self.activation_log = None\n",
    "        self.setup_flag = setup_flag\n",
    "        self.get_2d_rep_mean = get_2d_rep_mean\n",
    "        self.index = None\n",
    "\n",
    "    def setup(self,\n",
    "              dnn_model: nn.Module,\n",
    "              ind_dataloader,\n",
    "              layer_hook):\n",
    "\n",
    "        if not self.setup_flag:\n",
    "            print('\\n Get latent embeddings z from training set...')\n",
    "            activation_log = []\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            dnn_model.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for i, (image, label) in enumerate(ind_dataloader):\n",
    "                    image = image.to(device)\n",
    "                    pred_logits = dnn_model(image)\n",
    "                    \n",
    "                    latent_rep = layer_hook.output  # latent representation sample\n",
    "                    \n",
    "                    if self.get_2d_rep_mean:\n",
    "                        # Get image HxW mean:\n",
    "                        latent_rep = torch.mean(latent_rep, dim=2, keepdim=True)\n",
    "                        latent_rep = torch.mean(latent_rep, dim=3, keepdim=True)\n",
    "                        # Remove useless dimensions:\n",
    "                        latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "                        latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "                    \n",
    "                    # latent_rep = torch.flatten(layer_hook.output, 1)  # latent representation sample\n",
    "                    # ic(layer_hook.output)\n",
    "                    activation_log.append(\n",
    "                        normalizer(latent_rep.data.cpu().numpy()))\n",
    "\n",
    "            self.activation_log = np.concatenate(activation_log, axis=0)\n",
    "            self.index = faiss.IndexFlatL2(latent_rep.shape[1])\n",
    "            self.index.add(self.activation_log)\n",
    "            self.setup_flag = True\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def postprocess(self,\n",
    "                    dnn_model: nn.Module,\n",
    "                    dataloader: DataLoader,\n",
    "                    layer_hook):\n",
    "        \n",
    "        all_preds = []\n",
    "        all_kth_dist_score = []\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        dnn_model.to(device)\n",
    "        \n",
    "        for i, (image, label) in enumerate(dataloader):\n",
    "            image = image.to(device)\n",
    "            pred_logits = dnn_model(image)\n",
    "            # ic(layer_hook.output)\n",
    "            # latent_rep = torch.flatten(layer_hook.output, 1)  # latent representation sample\n",
    "            latent_rep = layer_hook.output  # latent representation sample\n",
    "            \n",
    "            if self.get_2d_rep_mean:\n",
    "                # Get image HxW mean:\n",
    "                latent_rep = torch.mean(latent_rep, dim=2, keepdim=True)\n",
    "                latent_rep = torch.mean(latent_rep, dim=3, keepdim=True)\n",
    "                # Remove useless dimensions:\n",
    "                latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "                latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "            \n",
    "            pred = torch.max(torch.softmax(pred_logits, dim=1), dim=1)\n",
    "            latent_rep_normed = normalizer(latent_rep.data.cpu().numpy())\n",
    "            \n",
    "            D, _ = self.index.search(\n",
    "                latent_rep_normed,\n",
    "                self.K)\n",
    "            kth_dist = -D[:, -1]\n",
    "            \n",
    "            all_preds.append(pred[0])\n",
    "            all_kth_dist_score.append(kth_dist)\n",
    "            \n",
    "        all_preds_t = torch.cat(all_preds)\n",
    "        # all_kth_dist_score_t = torch.cat(all_kth_dist_score)\n",
    "        all_kth_dist_score_np = np.concatenate(all_kth_dist_score, axis=0)\n",
    "        \n",
    "        return all_preds_t, all_kth_dist_score_np\n",
    "\n",
    "    def set_K_hyperparam(self, hyperparam: int = 50):\n",
    "        self.K = hyperparam\n",
    "\n",
    "    def get_K_hyperparam(self):\n",
    "        return self.K"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "source": [
    "ic(len(ws_dlv3p_train_loader));\n",
    "ic(len(ws_dlv3p_valid_loader));\n",
    "ic(len(ws_dlv3p_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(ws_dlv3p_anomaly_valid_loader));\n",
    "ic(len(ws_dlv3p_anomaly_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(cs_483640_dlv3p_valid_loader));\n",
    "ic(len(cs_483640_dlv3p_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(ws_soiling_483640_valid_loader));\n",
    "ic(len(ws_soiling_483640_test_loader));"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Model Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "source": [
    "ws_dlv3p_hook_dropblock2d_layer = Hook(ws_dlv3p_model.deeplab_v3plus_model.drop_block1)\n",
    "ws_dlv3p_hook_dropblock2d_layer"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Dist Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "source": [
    "knn_dist_ws_dlv3p = KNNPostprocessor(K=50, setup_flag=False, get_2d_rep_mean=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "source": [
    "knn_dist_ws_dlv3p.setup(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                        ws_dlv3p_train_loader,\n",
    "                        layer_hook=ws_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Kth-Dist Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "source": [
    "_, ind_ws_valid_kth_dist_score = knn_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                               ws_dlv3p_valid_loader,\n",
    "                                                               ws_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "\n",
    "_, ind_ws_test_kth_dist_score = knn_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                              ws_dlv3p_test_loader,\n",
    "                                                              ws_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "\n",
    "_, ood_ws_anomal_valid_kth_dist_score = knn_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                                      ws_dlv3p_anomaly_valid_loader,\n",
    "                                                                      ws_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "_, ood_ws_anomal_test_kth_dist_score = knn_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                                     ws_dlv3p_anomaly_test_loader,\n",
    "                                                                     ws_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "\n",
    "_, ood_cs_valid_kth_dist_score = knn_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                               cs_483640_dlv3p_valid_loader,\n",
    "                                                               ws_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "_, ood_cs_test_kth_dist_score = knn_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                              cs_483640_dlv3p_test_loader,\n",
    "                                                              ws_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "\n",
    "_, ood_ws_soil_valid_kth_dist_score = knn_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                                    ws_soiling_483640_valid_loader,\n",
    "                                                                    ws_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "_, ood_ws_soil_test_kth_dist_score = knn_dist_ws_dlv3p.postprocess(ws_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                                   ws_soiling_483640_test_loader,\n",
    "                                                                   ws_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "source": [
    "ind_ws_kth_dist_score = np.concatenate((ind_ws_valid_kth_dist_score, ind_ws_test_kth_dist_score))\n",
    "ood_ws_anomal_kth_dist_score = np.concatenate((ood_ws_anomal_valid_kth_dist_score, ood_ws_anomal_test_kth_dist_score))\n",
    "ood_cs_kth_dist_score = np.concatenate((ood_cs_valid_kth_dist_score, ood_cs_test_kth_dist_score))\n",
    "ood_ws_soil_kth_dist_score = np.concatenate((ood_ws_soil_valid_kth_dist_score, ood_ws_soil_test_kth_dist_score))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "knn_dist_score_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "source": [
    "np.save(knn_dist_score_path + 'ind_cs_kth_dist_score',\n",
    "        ind_ws_kth_dist_score)\n",
    "\n",
    "np.save(knn_dist_score_path + 'ood_cs_anomal_kth_dist_score',\n",
    "        ood_ws_anomal_kth_dist_score)\n",
    "\n",
    "np.save(knn_dist_score_path + 'ood_ws_kth_dist_score',\n",
    "        ood_cs_kth_dist_score)\n",
    "\n",
    "np.save(knn_dist_score_path + 'ood_ws_soil_kth_dist_score',\n",
    "        ood_ws_soil_kth_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "source": [
    "ic(ind_ws_kth_dist_score.shape);\n",
    "ic(ood_ws_anomal_kth_dist_score.shape);\n",
    "ic(ood_cs_kth_dist_score.shape);\n",
    "ic(ood_ws_soil_kth_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "source": [
    "df_kth_dist_scores_ws = pd.DataFrame(ind_ws_kth_dist_score, columns=[\"KNN Distance score\"])\n",
    "df_kth_dist_scores_ws_anomal = pd.DataFrame(ood_ws_anomal_kth_dist_score, columns=[\"KNN Distance score\"])\n",
    "df_kth_dist_scores_cs = pd.DataFrame(ood_cs_kth_dist_score, columns=[\"KNN Distance score\"])\n",
    "df_kth_dist_scores_ws_soil = pd.DataFrame(ood_ws_soil_kth_dist_score, columns=[\"KNN Distance score\"])\n",
    "\n",
    "df_kth_dist_scores_ws.insert(0, \"Dataset\", \"\")\n",
    "df_kth_dist_scores_ws.loc[:, \"Dataset\"] = \"woodscape\"\n",
    "\n",
    "df_kth_dist_scores_ws_anomal.insert(0, \"Dataset\", \"\")\n",
    "df_kth_dist_scores_ws_anomal.loc[:, \"Dataset\"] = \"woodscape-anomal\"\n",
    "\n",
    "df_kth_dist_scores_cs.insert(0, \"Dataset\", \"\")\n",
    "df_kth_dist_scores_cs.loc[:, \"Dataset\"] = \"cityscapes\"\n",
    "\n",
    "df_kth_dist_scores_ws_soil.insert(0, \"Dataset\", \"\")\n",
    "df_kth_dist_scores_ws_soil.loc[:, \"Dataset\"] = \"woodscape-soiling\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "source": [
    "df_pred_kth_dist_scores = pd.concat([df_kth_dist_scores_ws,\n",
    "                                     df_kth_dist_scores_ws_anomal]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_pred_kth_dist_scores, x=\"KNN Distance score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "source": [
    "ic(ind_ws_kth_dist_score.shape);\n",
    "ic(ood_ws_anomal_kth_dist_score.shape);\n",
    "ic(ood_cs_kth_dist_score.shape);\n",
    "ic(ood_ws_soil_kth_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woodscape vs. Woodscape-anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We align with the convention where positive (in-distribution) samples have higher scores (see plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "source": [
    "print(\"Test InD shape\", ind_ws_kth_dist_score.shape);\n",
    "print(\"Test OoD shape\", ood_ws_anomal_kth_dist_score.shape);\n",
    "\n",
    "results_kth_dist_gtsrb_anomaly = get_hz_detector_results(detect_exp_name=\"KNN Distance score: woodscape vs. woodscape-anomaly\",\n",
    "                                                         ind_samples_scores=ind_ws_kth_dist_score,\n",
    "                                                         ood_samples_scores=ood_ws_anomal_kth_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woodscape vs. Cityscapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We align with the convention where positive (in-distribution) samples have higher scores (see plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "source": [
    "print(\"Test InD shape\", ind_ws_kth_dist_score.shape);\n",
    "print(\"Test OoD shape\", ood_cs_kth_dist_score.shape);\n",
    "\n",
    "results_kth_dist_cifar10 = get_hz_detector_results(detect_exp_name=\"KNN Distance score: woodscape vs. cityscapes\",\n",
    "                                                 ind_samples_scores=ind_ws_kth_dist_score,\n",
    "                                                 ood_samples_scores=ood_cs_kth_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woodscape vs. Woodscape-soiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We align with the convention where positive (in-distribution) samples have higher scores (see plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "source": [
    "print(\"Test InD shape\", ind_ws_kth_dist_score.shape);\n",
    "print(\"Test OoD shape\", ood_ws_soil_kth_dist_score.shape);\n",
    "\n",
    "results_kth_dist_stl10 = get_hz_detector_results(detect_exp_name=\"KNN Distance score: woodscape vs. woodscape-soiling\",\n",
    "                                                 ind_samples_scores=ind_ws_kth_dist_score,\n",
    "                                                 ood_samples_scores=ood_ws_soil_kth_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Distance Score penultimate layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-Do! Results from this section are missing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "source": [
    "import faiss"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "source": [
    "class Hook:\n",
    "    \"\"\"\n",
    "    Hook class that returns the input and output of a layer during forward/backward pass\n",
    "    \"\"\"\n",
    "    def __init__(self, module: torch.nn.Module, backward: bool = False):\n",
    "        \"\"\"\n",
    "        Hook Class constructor\n",
    "        :param module: Layer block from Neural Network Module\n",
    "        :type module: torch.nn.Module\n",
    "        :param backward: backward-poss hook\n",
    "        :type backward: bool\n",
    "        \"\"\"\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        if not backward:\n",
    "            self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        else:\n",
    "            self.hook = module.register_backward_hook(self.hook_fn)\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "\n",
    "    def close(self):\n",
    "        self.hook.remove()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "source": [
    "normalizer = lambda x: x / (np.linalg.norm(x, ord=2, axis=-1, keepdims=True) + 1e-10)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "source": [
    "class KNNPostprocessor:\n",
    "    def __init__(self,\n",
    "                 K: int = 50,\n",
    "                 setup_flag: bool = False,\n",
    "                 get_2d_rep_mean: bool = False):\n",
    "        self.K = K\n",
    "        self.activation_log = None\n",
    "        self.setup_flag = setup_flag\n",
    "        self.get_2d_rep_mean = get_2d_rep_mean\n",
    "        self.index = None\n",
    "\n",
    "    def setup(self,\n",
    "              dnn_model: nn.Module,\n",
    "              ind_dataloader,\n",
    "              layer_hook):\n",
    "\n",
    "        if not self.setup_flag:\n",
    "            print('\\n Get latent embeddings z from training set...')\n",
    "            activation_log = []\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            dnn_model.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for i, (image, label) in enumerate(ind_dataloader):\n",
    "                    image = image.to(device)\n",
    "                    pred_logits = dnn_model(image)\n",
    "                    \n",
    "                    latent_rep = layer_hook.output  # latent representation sample\n",
    "                    \n",
    "                    if self.get_2d_rep_mean:\n",
    "                        # Get image HxW mean:\n",
    "                        latent_rep = torch.mean(latent_rep, dim=2, keepdim=True)\n",
    "                        latent_rep = torch.mean(latent_rep, dim=3, keepdim=True)\n",
    "                        # Remove useless dimensions:\n",
    "                        latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "                        latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "                    \n",
    "                    # latent_rep = torch.flatten(layer_hook.output, 1)  # latent representation sample\n",
    "                    # ic(layer_hook.output)\n",
    "                    activation_log.append(\n",
    "                        normalizer(latent_rep.data.cpu().numpy()))\n",
    "\n",
    "            self.activation_log = np.concatenate(activation_log, axis=0)\n",
    "            self.index = faiss.IndexFlatL2(latent_rep.shape[1])\n",
    "            self.index.add(self.activation_log)\n",
    "            self.setup_flag = True\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def postprocess(self,\n",
    "                    dnn_model: nn.Module,\n",
    "                    dataloader: DataLoader,\n",
    "                    layer_hook):\n",
    "        \n",
    "        all_preds = []\n",
    "        all_kth_dist_score = []\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        dnn_model.to(device)\n",
    "        \n",
    "        for i, (image, label) in enumerate(dataloader):\n",
    "            image = image.to(device)\n",
    "            pred_logits = dnn_model(image)\n",
    "            # ic(layer_hook.output)\n",
    "            # latent_rep = torch.flatten(layer_hook.output, 1)  # latent representation sample\n",
    "            latent_rep = layer_hook.output  # latent representation sample\n",
    "            \n",
    "            if self.get_2d_rep_mean:\n",
    "                # Get image HxW mean:\n",
    "                latent_rep = torch.mean(latent_rep, dim=2, keepdim=True)\n",
    "                latent_rep = torch.mean(latent_rep, dim=3, keepdim=True)\n",
    "                # Remove useless dimensions:\n",
    "                latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "                latent_rep = torch.squeeze(latent_rep, dim=2)\n",
    "            \n",
    "            pred = torch.max(torch.softmax(pred_logits, dim=1), dim=1)\n",
    "            latent_rep_normed = normalizer(latent_rep.data.cpu().numpy())\n",
    "            \n",
    "            D, _ = self.index.search(\n",
    "                latent_rep_normed,\n",
    "                self.K)\n",
    "            kth_dist = -D[:, -1]\n",
    "            \n",
    "            all_preds.append(pred[0])\n",
    "            all_kth_dist_score.append(kth_dist)\n",
    "            \n",
    "        all_preds_t = torch.cat(all_preds)\n",
    "        # all_kth_dist_score_t = torch.cat(all_kth_dist_score)\n",
    "        all_kth_dist_score_np = np.concatenate(all_kth_dist_score, axis=0)\n",
    "        \n",
    "        return all_preds_t, all_kth_dist_score_np\n",
    "\n",
    "    def set_K_hyperparam(self, hyperparam: int = 50):\n",
    "        self.K = hyperparam\n",
    "\n",
    "    def get_K_hyperparam(self):\n",
    "        return self.K"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "source": [
    "ic(len(cs_dlv3p_train_loader));\n",
    "ic(len(cs_dlv3p_valid_loader));\n",
    "ic(len(cs_dlv3p_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(cs_dlv3p_anomaly_valid_loader));\n",
    "ic(len(cs_dlv3p_anomaly_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(ws_256512_dlv3p_valid_loader));\n",
    "ic(len(ws_256512_dlv3p_test_loader));\n",
    "ic(\"========================================\");\n",
    "ic(len(ws_soiling_256512_valid_loader));\n",
    "ic(len(ws_soiling_256512_test_loader));"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Model Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "source": [
    "cs_dlv3p_hook_penultimate_layer = Hook(cs_dlv3p_model.deeplab_v3plus_model.classifier.classifier[2])\n",
    "cs_dlv3p_hook_penultimate_layer"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Dist Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "source": [
    "knn_dist_cs_dlv3p = KNNPostprocessor(K=50, setup_flag=False, get_2d_rep_mean=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "source": [
    "knn_dist_cs_dlv3p.setup(cs_dlv3p_model.deeplab_v3plus_model,\n",
    "                        cs_dlv3p_train_loader,\n",
    "                        layer_hook=cs_dlv3p_hook_penultimate_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Kth-Dist Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "source": [
    "_, ind_cs_valid_kth_dist_score = knn_dist_cs_dlv3p.postprocess(cs_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                               cs_dlv3p_valid_loader,\n",
    "                                                               cs_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "\n",
    "_, ind_cs_test_kth_dist_score = knn_dist_cs_dlv3p.postprocess(cs_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                              cs_dlv3p_test_loader,\n",
    "                                                              cs_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "\n",
    "_, ood_cs_anomal_valid_kth_dist_score = knn_dist_cs_dlv3p.postprocess(cs_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                                      cs_dlv3p_anomaly_valid_loader,\n",
    "                                                                      cs_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "_, ood_cs_anomal_test_kth_dist_score = knn_dist_cs_dlv3p.postprocess(cs_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                                     cs_dlv3p_anomaly_test_loader,\n",
    "                                                                     cs_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "\n",
    "_, ood_ws_valid_kth_dist_score = knn_dist_cs_dlv3p.postprocess(cs_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                               ws_256512_dlv3p_valid_loader,\n",
    "                                                               cs_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "_, ood_ws_test_kth_dist_score = knn_dist_cs_dlv3p.postprocess(cs_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                              ws_256512_dlv3p_test_loader,\n",
    "                                                              cs_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "\n",
    "_, ood_ws_soil_valid_kth_dist_score = knn_dist_cs_dlv3p.postprocess(cs_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                                    ws_soiling_256512_valid_loader,\n",
    "                                                                    cs_dlv3p_hook_penultimate_layer)\n",
    "\n",
    "_, ood_ws_soil_test_kth_dist_score = knn_dist_cs_dlv3p.postprocess(cs_dlv3p_model.deeplab_v3plus_model,\n",
    "                                                                   ws_soiling_256512_test_loader,\n",
    "                                                                   cs_dlv3p_hook_penultimate_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "source": [
    "ind_cs_kth_dist_score = np.concatenate((ind_cs_valid_kth_dist_score, ind_cs_test_kth_dist_score))\n",
    "ood_cs_anomal_kth_dist_score = np.concatenate((ood_cs_anomal_valid_kth_dist_score, ood_cs_anomal_test_kth_dist_score))\n",
    "ood_ws_kth_dist_score = np.concatenate((ood_ws_valid_kth_dist_score, ood_ws_test_kth_dist_score))\n",
    "ood_ws_soil_kth_dist_score = np.concatenate((ood_ws_soil_valid_kth_dist_score, ood_ws_soil_test_kth_dist_score))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "knn_dist_penultimate_layer_score_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "source": [
    "np.save(knn_dist_penultimate_layer_score_path + 'ind_cs_kth_dist_score',\n",
    "        ind_cs_kth_dist_score)\n",
    "\n",
    "np.save(knn_dist_penultimate_layer_score_path + 'ood_cs_anomal_kth_dist_score',\n",
    "        ood_cs_anomal_kth_dist_score)\n",
    "\n",
    "np.save(knn_dist_penultimate_layer_score_path + 'ood_ws_kth_dist_score',\n",
    "        ood_ws_kth_dist_score)\n",
    "\n",
    "np.save(knn_dist_penultimate_layer_score_path + 'ood_ws_soil_kth_dist_score',\n",
    "        ood_ws_soil_kth_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "source": [
    "ic(ind_cs_kth_dist_score.shape);\n",
    "ic(ood_cs_anomal_kth_dist_score.shape);\n",
    "ic(ood_ws_kth_dist_score.shape);\n",
    "ic(ood_ws_soil_kth_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "source": [
    "df_kth_dist_scores_cs = pd.DataFrame(ind_cs_kth_dist_score, columns=[\"KNN Distance score\"])\n",
    "df_kth_dist_scores_cs_anomal = pd.DataFrame(ood_cs_anomal_kth_dist_score, columns=[\"KNN Distance score\"])\n",
    "df_kth_dist_scores_ws = pd.DataFrame(ood_ws_kth_dist_score, columns=[\"KNN Distance score\"])\n",
    "df_kth_dist_scores_ws_soil = pd.DataFrame(ood_ws_soil_kth_dist_score, columns=[\"KNN Distance score\"])\n",
    "\n",
    "df_kth_dist_scores_cs.insert(0, \"Dataset\", \"\")\n",
    "df_kth_dist_scores_cs.loc[:, \"Dataset\"] = \"cityscapes\"\n",
    "\n",
    "df_kth_dist_scores_cs_anomal.insert(0, \"Dataset\", \"\")\n",
    "df_kth_dist_scores_cs_anomal.loc[:, \"Dataset\"] = \"cityscapes-anomal\"\n",
    "\n",
    "df_kth_dist_scores_ws.insert(0, \"Dataset\", \"\")\n",
    "df_kth_dist_scores_ws.loc[:, \"Dataset\"] = \"woodscape\"\n",
    "\n",
    "df_kth_dist_scores_ws_soil.insert(0, \"Dataset\", \"\")\n",
    "df_kth_dist_scores_ws_soil.loc[:, \"Dataset\"] = \"woodscape-soiling\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "source": [
    "df_pred_kth_dist_scores = pd.concat([df_kth_dist_scores_cs,\n",
    "                                     df_kth_dist_scores_cs_anomal]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_pred_kth_dist_scores, x=\"KNN Distance score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "source": [
    "ic(ind_cs_kth_dist_score.shape);\n",
    "ic(ood_cs_anomal_kth_dist_score.shape);\n",
    "ic(ood_ws_kth_dist_score.shape);\n",
    "ic(ood_ws_soil_kth_dist_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes vs. Cityscapes-anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We align with the convention where positive (in-distribution) samples have higher scores (see plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "source": [
    "print(\"Test InD shape\", ind_cs_kth_dist_score.shape);\n",
    "print(\"Test OoD shape\", ood_cs_anomal_kth_dist_score.shape);\n",
    "\n",
    "results_kth_dist_gtsrb_anomaly = get_hz_detector_results(detect_exp_name=\"KNN Distance score: cityscapes vs. cityscapes-anomaly\",\n",
    "                                                         ind_samples_scores=ind_cs_kth_dist_score,\n",
    "                                                         ood_samples_scores=ood_cs_anomal_kth_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes vs. Woodscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We align with the convention where positive (in-distribution) samples have higher scores (see plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "source": [
    "print(\"Test InD shape\", ind_cs_kth_dist_score.shape);\n",
    "print(\"Test OoD shape\", ood_ws_kth_dist_score.shape);\n",
    "\n",
    "results_kth_dist_cifar10 = get_hz_detector_results(detect_exp_name=\"KNN Distance score: cityscapes vs. woodscape\",\n",
    "                                                 ind_samples_scores=ind_cs_kth_dist_score,\n",
    "                                                 ood_samples_scores=ood_ws_kth_dist_score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes vs. Woodscape-soiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We align with the convention where positive (in-distribution) samples have higher scores (see plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "source": [
    "print(\"Test InD shape\", ind_cs_kth_dist_score.shape);\n",
    "print(\"Test OoD shape\", ood_ws_soil_kth_dist_score.shape);\n",
    "\n",
    "results_kth_dist_stl10 = get_hz_detector_results(detect_exp_name=\"KNN Distance score: cityscapes vs. woodscape-soiling\",\n",
    "                                                 ind_samples_scores=ind_cs_kth_dist_score,\n",
    "                                                 ood_samples_scores=ood_ws_soil_kth_dist_score)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Semantic_Segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

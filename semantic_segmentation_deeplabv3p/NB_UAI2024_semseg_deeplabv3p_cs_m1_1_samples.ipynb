{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "from icecream import ic"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchvision import transforms as transform_lib\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "from dataset.cityscapes import Cityscapes\n",
    "from dataset.cityscapes import CityscapesDataModule\n",
    "from dataset.woodscape import WoodScapeDataset\n",
    "from dataset.woodscape import WoodScapeDataModule\n",
    "from dataset import WoodScapeSoilingDataset\n",
    "from dataset import WoodScapeSoilingDataModule"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "from utils.display_images import denormalize_img\n",
    "from utils import show_dataset_image, show_dataset_mask\n",
    "from utils import show_prediction_images, show_prediction_uncertainty_images"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "from deeplab_v3p import DeepLabV3PlusModule\n",
    "from dropblock import DropBlock2D"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "from ls_ood_detect.uncertainty_estimation import Hook\n",
    "from ls_ood_detect.uncertainty_estimation import deeplabv3p_get_ls_mcd_samples\n",
    "from ls_ood_detect.uncertainty_estimation import get_dl_h_z\n",
    "from ls_ood_detect.ood_detection_dataset import build_ood_detection_ds\n",
    "from ls_ood_detect.dimensionality_reduction import plot_samples_pacmap\n",
    "from ls_ood_detect.detectors import KDEClassifier\n",
    "from ls_ood_detect.metrics import get_ood_detector_results, plot_roc_ood_detector"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution Shift Detection Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for using the package:\n",
    "\n",
    "1. Load you Dataloader Pytorch-Lightning Module\n",
    "2. Load your trained DNN PyTorch-Lightning Module\n",
    "3. Add Hook to DNN Module for MC samples extraction\n",
    "4. Get Monte-Carlo (MC) samples for In-Distribution (InD) samples dataloader, and Out-of-Distribution (OoD) samples dataloader\n",
    "5. Get Entropy from InD and OoD MC samples\n",
    "6. Build OoD Detection dataset (with InD and OoD samples)\n",
    "7. Build OoD data-driven Detector (classifier)\n",
    "8. Show OoD performance results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cityscapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "dataset_path = './Data/DATASETS/CityScapes'\n",
    "batch_size = 1"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cityscapes img_size (256, 512)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "cs_dm_normal_dlv3p = CityscapesDataModule(data_dir=dataset_path,\n",
    "                                          batch_size=batch_size,\n",
    "                                          target_type='semantic',\n",
    "                                          img_size=(256, 512),\n",
    "                                          num_workers=10,\n",
    "                                          drop_last=True,\n",
    "                                          default_transforms=False, # Here this should be True!\n",
    "                                          default_img_mask_transforms=True) # And here this should be False!"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "cs_dm_normal_2_dlv3p = CityscapesDataModule(data_dir=dataset_path,\n",
    "                                          batch_size=batch_size,\n",
    "                                          target_type='semantic',\n",
    "                                          img_size=(256, 512),\n",
    "                                          num_workers=10,\n",
    "                                          drop_last=True,\n",
    "                                          default_transforms=False, # Here this should be True!\n",
    "                                          default_img_mask_transforms=True) # And here this should be False!"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "cs_dm_normal_2_dlv3p.train_img_mask_transforms = cs_dm_normal_2_dlv3p.val_img_mask_transforms"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "cs_dm_normal_2_dlv3p.train_img_mask_transforms"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "cs_dm_normal_2_dlv3p.val_img_mask_transforms"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cityscapes img_size (483, 640)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "\n",
    "cs_483640_dm_dlv3p = CityscapesDataModule(data_dir=dataset_path,\n",
    "                                          batch_size=batch_size,\n",
    "                                          target_type='semantic',\n",
    "                                          img_size=(483, 640),\n",
    "                                          num_workers=10,\n",
    "                                          drop_last=True,\n",
    "                                          default_transforms=True, # Here this should be True!\n",
    "                                          default_img_mask_transforms=False) # And here this should be False!        "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cityscapes-Anomalies img_size (256, 512)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "cs_dm_anomal_dlv3p = CityscapesDataModule(data_dir=dataset_path,\n",
    "                                          batch_size=batch_size,\n",
    "                                          target_type='semantic',\n",
    "                                          img_size=(256, 512),\n",
    "                                          num_workers=10,\n",
    "                                          drop_last=True,\n",
    "                                          default_transforms=False, # Here this should be False!\n",
    "                                          default_img_mask_transforms=True) # And here this should be True! (Enable Anomalies)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "cs_dlv3p_train_loader = cs_dm_normal_dlv3p.train_dataloader()\n",
    "cs_dlv3p_valid_loader = cs_dm_normal_dlv3p.val_dataloader()\n",
    "cs_dlv3p_test_loader = cs_dm_normal_dlv3p.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "cs_dlv3p_anomaly_valid_loader = cs_dm_anomal_dlv3p.anomaly_val_dataloader()\n",
    "cs_dlv3p_anomaly_test_loader = cs_dm_anomal_dlv3p.anomaly_test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "cs_483640_dlv3p_valid_loader = cs_483640_dm_dlv3p.val_dataloader()\n",
    "cs_483640_dlv3p_test_loader = cs_483640_dm_dlv3p.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "ic(len(cs_dlv3p_train_loader));\n",
    "ic(len(cs_dlv3p_valid_loader));\n",
    "ic(len(cs_dlv3p_test_loader));\n",
    "ic(len(cs_dlv3p_anomaly_valid_loader));\n",
    "ic(len(cs_dlv3p_anomaly_test_loader));"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "cs_dlv3p_train_loader_2 = cs_dm_normal_2_dlv3p.train_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woodscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "ws_dataset_path = './Data/DATASETS/WoodScape/'\n",
    "batch_size = 1\n",
    "\n",
    "cmap = {0: [0, 0, 0],  # \"void\"\n",
    "        1: [128, 64, 128],  # \"road\",\n",
    "        2: [69, 76, 11],  # \"lanemarks\",\n",
    "        3: [0, 255, 0],  # \"curb\",\n",
    "        4: [220, 20, 60],  # \"person\",\n",
    "        5: [255, 0, 0],  # \"rider\",\n",
    "        6: [0, 0, 142],  # \"vehicles\",\n",
    "        7: [119, 11, 32],  # \"bicycle\",\n",
    "        8: [0, 0, 230],  # \"motorcycle\",\n",
    "        9: [220, 220, 0]  # \"traffic_sign\",\n",
    "        }\n",
    "\n",
    "# same values as in VainF Repository! - Probably not the best Values for Woodscapes!\n",
    "ws_dlv3p_norm_mean = [0.485, 0.456, 0.406]\n",
    "ws_dlv3p_norm_std = [0.229, 0.224, 0.225]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape img_size (483, 640)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "ws_dm_normal_dlv3p = WoodScapeDataModule(dataset_dir=ws_dataset_path,\n",
    "                                         img_size=(483, 640),\n",
    "                                         batch_size=batch_size,\n",
    "                                         default_transforms=True,\n",
    "                                         label_colours=cmap,\n",
    "                                         norm_mean=ws_dlv3p_norm_mean,\n",
    "                                         norm_std=ws_dlv3p_norm_std,\n",
    "                                         seed=9290,\n",
    "                                         drop_last=True)\n",
    "ws_dm_normal_dlv3p.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape img_size (256, 512)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "ws_dm_normal_dlv3p_256_512 = WoodScapeDataModule(dataset_dir=ws_dataset_path,\n",
    "                                         img_size=(256, 512),\n",
    "                                         batch_size=batch_size,\n",
    "                                         default_transforms=True,\n",
    "                                         label_colours=cmap,\n",
    "                                         norm_mean=ws_dlv3p_norm_mean,\n",
    "                                         norm_std=ws_dlv3p_norm_std,\n",
    "                                         seed=9290,\n",
    "                                         drop_last=True)\n",
    "ws_dm_normal_dlv3p_256_512.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape-Anomalies img_size (483, 640)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "ws_dm_anomal_dlv3p = WoodScapeDataModule(dataset_dir=ws_dataset_path,\n",
    "                                         img_size=(483, 640),\n",
    "                                         batch_size=batch_size,\n",
    "                                         default_transforms=True,\n",
    "                                         label_colours=cmap,\n",
    "                                         norm_mean=ws_dlv3p_norm_mean,\n",
    "                                         norm_std=ws_dlv3p_norm_std,\n",
    "                                         seed=9290,\n",
    "                                         drop_last=True)\n",
    "ws_dm_anomal_dlv3p.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woodscape dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "ws_dlv3p_train_loader = ws_dm_normal_dlv3p.train_dataloader()\n",
    "ws_dlv3p_valid_loader = ws_dm_normal_dlv3p.val_dataloader()\n",
    "ws_dlv3p_test_loader = ws_dm_normal_dlv3p.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "ws_dlv3p_anomaly_valid_loader = ws_dm_anomal_dlv3p.anomaly_val_dataloader()\n",
    "ws_dlv3p_anomaly_test_loader = ws_dm_anomal_dlv3p.anomaly_test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "ws_256512_dlv3p_valid_loader = ws_dm_normal_dlv3p_256_512.val_dataloader()\n",
    "ws_256512_dlv3p_test_loader = ws_dm_normal_dlv3p_256_512.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "source": [
    "ic(len(ws_256512_dlv3p_valid_loader));\n",
    "ic(len(ws_256512_dlv3p_test_loader));"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woodscape-Soiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape Soling OoD DeeplabV3+ (483, 640)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "source": [
    "woodscape_soil_483640_dm = WoodScapeSoilingDataModule(dataset_dir=\",/Data/DATASETS/WoodScape/soiling_dataset/\",\n",
    "                                                      img_size=(483, 640),\n",
    "                                                      batch_size=1,\n",
    "                                                      default_transforms=True,\n",
    "                                                      seed=9290)\n",
    "woodscape_soil_483640_dm.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Woodscape Soling OoD DeeplabV3+ (256, 512)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "source": [
    "woodscape_soil_256512_dm = WoodScapeSoilingDataModule(dataset_dir=\"./Data/DATASETS/WoodScape/soiling_dataset/\",\n",
    "                                                      img_size=(256, 512),\n",
    "                                                      batch_size=1,\n",
    "                                                      default_transforms=True,\n",
    "                                                      seed=9290)\n",
    "woodscape_soil_256512_dm.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "source": [
    "ws_soiling_483640_valid_loader = woodscape_soil_483640_dm.val_dataloader()\n",
    "ws_soiling_483640_test_loader = woodscape_soil_483640_dm.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "source": [
    "ws_soiling_256512_valid_loader = woodscape_soil_256512_dm.val_dataloader()\n",
    "ws_soiling_256512_test_loader = woodscape_soil_256512_dm.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "ic(len(ws_soiling_256512_valid_loader));\n",
    "ic(len(ws_soiling_256512_test_loader));"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "dataiter_cs_train = iter(cs_dlv3p_train_loader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "source": [
    "batch_ws_data, batch_ws_labels = dataiter_cs_train.next()\n",
    "plt.figure()\n",
    "show_dataset_image(batch_ws_data[0], cs_dm_anomal_dlv3p.norm_mean, cs_dm_anomal_dlv3p.norm_std)\n",
    "plt.figure()\n",
    "show_dataset_mask(batch_ws_labels[0].squeeze(), cs_dlv3p_train_loader.dataset.decode_target)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes-Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "source": [
    "dataiter_cs_anomaly_valid = iter(cs_dlv3p_anomaly_valid_loader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "source": [
    "batch_ws_data, batch_ws_labels = dataiter_cs_anomaly_valid.next()\n",
    "plt.figure()\n",
    "show_dataset_image(batch_ws_data[0], cs_dm_anomal_dlv3p.norm_mean, cs_dm_anomal_dlv3p.norm_std)\n",
    "plt.figure()\n",
    "show_dataset_mask(batch_ws_labels[0].squeeze(), cs_dlv3p_train_loader.dataset.decode_target)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woodscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "source": [
    "dataiter_ws_soiling_valid = iter(ws_256512_dlv3p_valid_loader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "batch_ws_soil_data, batch_ws_soil_labels = dataiter_ws_soiling_valid.next()\n",
    "plt.figure()\n",
    "show_dataset_image(batch_ws_soil_data[0], ws_dm_normal_dlv3p_256_512.norm_mean, ws_dm_normal_dlv3p_256_512.norm_std)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woodscape-Soiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "source": [
    "dataiter_ws_soiling_valid = iter(ws_soiling_256512_valid_loader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "source": [
    "batch_ws_soil_data, batch_ws_soil_labels = dataiter_ws_soiling_valid.next()\n",
    "plt.figure()\n",
    "show_dataset_image(batch_ws_soil_data[0], ws_dm_normal_dlv3p_256_512.norm_mean, ws_dm_normal_dlv3p_256_512.norm_std)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplabv3+ Cityscapes Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "cs_dlv3p_path = \"./lightning_logs/version_158692/checkpoints/epoch=403-step=18584.ckpt\"\n",
    "cs_dlv3p_model = DeepLabV3PlusModule.load_from_checkpoint(checkpoint_path=cs_dlv3p_path)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "ic(cs_dlv3p_model.pred_loss_type);\n",
    "ic(cs_dlv3p_model.n_class);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "cs_dlv3p_model.eval();"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "cs_dlv3p_model.backbone_name"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "cs_dlv3p_model"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Hook Deeplabv3+ Woodscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "ic(cs_dlv3p_model.deeplab_v3plus_model.drop_block1);\n",
    "ic(cs_dlv3p_model.deeplab_v3plus_model.drop_block1.block_size);\n",
    "ic(cs_dlv3p_model.deeplab_v3plus_model.drop_block1.drop_prob);\n",
    "ic(cs_dlv3p_model.deeplab_v3plus_model.drop_block1.training);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "source": [
    "cs_dlv3p_hook_dropblock2d_layer = Hook(cs_dlv3p_model.deeplab_v3plus_model.drop_block1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Monte Carlo Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "source": [
    "# Monte Carlo Dropout - Enable Dropout @ Test Time!\n",
    "def deeplabv3p_apply_dropout(m):\n",
    "    if type(m) == torch.nn.Dropout or type(m) == DropBlock2D:\n",
    "        m.train()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "source": [
    "mc_samples = 16"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "source": [
    "cs_dlv3p_model.deeplab_v3plus_model.to(device);\n",
    "cs_dlv3p_model.deeplab_v3plus_model.eval(); \n",
    "cs_dlv3p_model.deeplab_v3plus_model.apply(deeplabv3p_apply_dropout); # enable dropout"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "source": [
    "ic(cs_dlv3p_model.deeplab_v3plus_model.drop_block1.drop_prob);\n",
    "ic(cs_dlv3p_model.deeplab_v3plus_model.drop_block1.training);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "source": [
    "cs_dlv3p_cs_normal_train_16mc_samples = deeplabv3p_get_ls_mcd_samples(cs_dlv3p_model,\n",
    "                                                                      cs_dlv3p_train_loader,\n",
    "                                                                      mc_samples,\n",
    "                                                                      cs_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "source": [
    "cs_dlv3p_cs_normal_train_2_16mc_samples = deeplabv3p_get_ls_mcd_samples(cs_dlv3p_model,\n",
    "                                                                        cs_dlv3p_train_loader_2,\n",
    "                                                                        mc_samples,\n",
    "                                                                        cs_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "source": [
    "cs_dlv3p_cs_normal_valid_16mc_samples = deeplabv3p_get_ls_mcd_samples(cs_dlv3p_model,\n",
    "                                                                      cs_dlv3p_valid_loader,\n",
    "                                                                      mc_samples,\n",
    "                                                                      cs_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "cs_dlv3p_cs_normal_test_16mc_samples = deeplabv3p_get_ls_mcd_samples(cs_dlv3p_model,\n",
    "                                                                     cs_dlv3p_test_loader,\n",
    "                                                                     mc_samples,\n",
    "                                                                     cs_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "source": [
    "cs_dlv3p_cs_anomal_valid_16mc_samples = deeplabv3p_get_ls_mcd_samples(cs_dlv3p_model,\n",
    "                                                                      cs_dlv3p_anomaly_valid_loader,\n",
    "                                                                      mc_samples,\n",
    "                                                                      cs_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "cs_dlv3p_cs_anomal_test_16mc_samples = deeplabv3p_get_ls_mcd_samples(cs_dlv3p_model,\n",
    "                                                                     cs_dlv3p_anomaly_test_loader,\n",
    "                                                                     mc_samples,\n",
    "                                                                     cs_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "source": [
    "cs_dlv3p_ws_256512_valid_16mc_samples = deeplabv3p_get_ls_mcd_samples(cs_dlv3p_model,\n",
    "                                                                      ws_256512_dlv3p_valid_loader,\n",
    "                                                                      mc_samples,\n",
    "                                                                      cs_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "cs_dlv3p_ws_256512_test_16mc_samples = deeplabv3p_get_ls_mcd_samples(cs_dlv3p_model,\n",
    "                                                                     ws_256512_dlv3p_test_loader,\n",
    "                                                                     mc_samples,\n",
    "                                                                     cs_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "source": [
    "cs_dlv3p_ws_soiling_2565152_valid_16mc_samples = deeplabv3p_get_ls_mcd_samples(cs_dlv3p_model,\n",
    "                                                                              ws_soiling_256512_valid_loader,\n",
    "                                                                              mc_samples,\n",
    "                                                                              cs_dlv3p_hook_dropblock2d_layer)\n",
    "\n",
    "cs_dlv3p_ws_soiling_2565152_test_16mc_samples = deeplabv3p_get_ls_mcd_samples(cs_dlv3p_model,\n",
    "                                                                             ws_soiling_256512_test_loader,\n",
    "                                                                             mc_samples,\n",
    "                                                                             cs_dlv3p_hook_dropblock2d_layer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "source": [
    "torch.save(cs_dlv3p_cs_normal_train_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_cs_normal_train_16mc_samples.pt')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "source": [
    "torch.save(cs_dlv3p_cs_normal_train_2_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_cs_normal_train_2_16mc_samples.pt')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "source": [
    "torch.save(cs_dlv3p_cs_normal_valid_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_cs_normal_valid_16mc_samples.pt')\n",
    "torch.save(cs_dlv3p_cs_normal_test_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_cs_normal_test_16mc_samples.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "source": [
    "torch.save(cs_dlv3p_cs_anomal_valid_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_cs_anomal_valid_16mc_samples.pt')\n",
    "torch.save(cs_dlv3p_cs_anomal_test_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_cs_anomal_test_16mc_samples.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "source": [
    "torch.save(cs_dlv3p_ws_256512_valid_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_ws_256512_valid_16mc_samples.pt')\n",
    "torch.save(cs_dlv3p_ws_256512_test_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_ws_256512_test_16mc_samples.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "source": [
    "cs_dlv3p_ws_soiling_256512_valid_16mc_samples = cs_dlv3p_ws_soiling_2565152_valid_16mc_samples\n",
    "cs_dlv3p_ws_soiling_256512_test_16mc_samples = cs_dlv3p_ws_soiling_2565152_test_16mc_samples"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "source": [
    "torch.save(cs_dlv3p_ws_soiling_256512_valid_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_ws_soiling_2565152_valid_16mc_samples.pt')\n",
    "torch.save(cs_dlv3p_ws_soiling_256512_test_16mc_samples,\n",
    "           './Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_ws_soiling_2565152_test_16mc_samples.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "source": [
    "cs_dlv3p_cs_normal_train_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_cs_normal_train_16mc_samples.pt')\n",
    "cs_dlv3p_cs_normal_valid_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/ws_dlv3p_ws_normal_valid_16mc_samples.pt')\n",
    "cs_dlv3p_cs_normal_test_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/ws_dlv3p_ws_normal_test_16mc_samples.pt')\n",
    "\n",
    "ws_dlv3p_ws_anomal_valid_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/ws_dlv3p_ws_anomal_valid_16mc_samples.pt')\n",
    "ws_dlv3p_ws_anomal_test_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/ws_dlv3p_ws_anomal_test_16mc_samples.pt')\n",
    "\n",
    "cs_dlv3p_ws_256512_valid_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_ws_256512_valid_16mc_samples.pt')\n",
    "cs_dlv3p_ws_256512_test_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_ws_256512_test_16mc_samples.pt')\n",
    "\n",
    "cs_dlv3p_ws_soiling_256512_valid_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_ws_soiling_256512_valid_16mc_samples.pt')\n",
    "cs_dlv3p_ws_soiling_256512_test_16mc_samples = torch.load('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/mc_samples/cs_dlv3p_ws_soiling_256512_test_16mc_samples.pt')"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "source": [
    "_, cs_dlv3p_h_z_cs_normal_train_samples_np = get_dl_h_z(cs_dlv3p_cs_normal_train_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "source": [
    "_, cs_dlv3p_h_z_cs_normal_train_2_samples_np = get_dl_h_z(cs_dlv3p_cs_normal_train_2_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "source": [
    "_, cs_dlv3p_h_z_cs_normal_valid_samples_np = get_dl_h_z(cs_dlv3p_cs_normal_valid_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "source": [
    "_, cs_dlv3p_h_z_cs_normal_test_samples_np = get_dl_h_z(cs_dlv3p_cs_normal_test_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "source": [
    "_, cs_dlv3p_h_z_cs_anomal_valid_samples_np = get_dl_h_z(cs_dlv3p_cs_anomal_valid_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "source": [
    "_, cs_dlv3p_h_z_cs_anomal_test_samples_np = get_dl_h_z(cs_dlv3p_cs_anomal_test_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "source": [
    "_, cs_dlv3p_h_z_ws_256512_valid_samples_np = get_dl_h_z(cs_dlv3p_ws_256512_valid_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "source": [
    "_, cs_dlv3p_h_z_ws_256512_test_samples_np = get_dl_h_z(cs_dlv3p_ws_256512_test_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "source": [
    "_, cs_dlv3p_h_z_ws_soil_256512_valid_samples_np = get_dl_h_z(cs_dlv3p_ws_soiling_256512_valid_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "source": [
    "_, cs_dlv3p_h_z_ws_soil_256512_test_samples_np = get_dl_h_z(cs_dlv3p_ws_soiling_256512_test_16mc_samples, mcd_samples_nro=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "source": [
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/entropy/cs_dlv3p_h_z_cs_normal_train_samples_np',\n",
    "        cs_dlv3p_h_z_cs_normal_train_samples_np)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "source": [
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/entropy/cs_dlv3p_h_z_cs_normal_train_2_samples_np',\n",
    "        cs_dlv3p_h_z_cs_normal_train_2_samples_np)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "source": [
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/entropy/cs_dlv3p_h_z_cs_normal_valid_samples_np',\n",
    "        cs_dlv3p_h_z_cs_normal_valid_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/entropy/cs_dlv3p_h_z_cs_normal_test_samples_np',\n",
    "        cs_dlv3p_h_z_cs_normal_test_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/entropy/cs_dlv3p_h_z_cs_anomal_valid_samples_np',\n",
    "        cs_dlv3p_h_z_cs_anomal_valid_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/entropy/cs_dlv3p_h_z_cs_anomal_test_samples_np',\n",
    "        cs_dlv3p_h_z_cs_anomal_test_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/entropy/cs_dlv3p_h_z_ws_256512_valid_samples_np',\n",
    "        cs_dlv3p_h_z_ws_256512_valid_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/entropy/cs_dlv3p_h_z_ws_256512_test_samples_np',\n",
    "        cs_dlv3p_h_z_ws_256512_test_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/entropy/cs_dlv3p_h_z_ws_soil_256512_valid_samples_np',\n",
    "        cs_dlv3p_h_z_ws_soil_256512_valid_samples_np)\n",
    "\n",
    "np.save('./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/entropy/cs_dlv3p_h_z_ws_soil_256512_test_samples_np',\n",
    "        cs_dlv3p_h_z_ws_soil_256512_test_samples_np)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "source": [
    "cs_dlv3p_cs_normal_train_16mc_samples[10:18]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "cs_dlv3p_h_z_cs_normal_train_samples_np"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Semantic_Segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

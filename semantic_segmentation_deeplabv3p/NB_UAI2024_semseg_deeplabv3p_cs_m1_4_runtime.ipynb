{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "from icecream import ic"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchvision import transforms as transform_lib\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from dropblock import DropBlock2D"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "from dataset.cityscapes import Cityscapes\n",
    "from dataset.cityscapes import CityscapesDataModule\n",
    "from dataset.woodscape import WoodScapeDataset\n",
    "from dataset.woodscape import WoodScapeDataModule\n",
    "from dataset import WoodScapeSoilingDataset\n",
    "from dataset import WoodScapeSoilingDataModule"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "from dataset.cityscapes import Cityscapes\n",
    "from dataset.cityscapes import CityscapesDataModule\n",
    "from dataset.woodscape import WoodScapeDataset\n",
    "from dataset.woodscape import WoodScapeDataModule\n",
    "from dataset import WoodScapeSoilingDataset\n",
    "from dataset import WoodScapeSoilingDataModule"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "from utils.display_images import denormalize_img\n",
    "from utils import show_dataset_image, show_dataset_mask\n",
    "from utils import show_prediction_images, show_prediction_uncertainty_images"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "from deeplab_v3p import DeepLabV3PlusModule\n",
    "from dropblock import DropBlock2D"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "from ls_ood_detect.uncertainty_estimation import Hook\n",
    "from ls_ood_detect.uncertainty_estimation import deeplabv3p_get_ls_mcd_samples\n",
    "from ls_ood_detect.uncertainty_estimation import get_latent_represent_mcd_samples\n",
    "from ls_ood_detect.uncertainty_estimation import get_dl_h_z\n",
    "from ls_ood_detect.ood_detection_dataset import build_ood_detection_ds\n",
    "from ls_ood_detect.dimensionality_reduction import plot_samples_pacmap\n",
    "from ls_ood_detect.detectors import KDEClassifier, DetectorKDE\n",
    "from ls_ood_detect.score import get_hz_scores\n",
    "from ls_ood_detect.metrics import get_hz_detector_results\n",
    "from ls_ood_detect.metrics import get_ood_detector_results\n",
    "from ls_ood_detect.metrics import plot_roc_ood_detector\n",
    "from ls_ood_detect.metrics import plot_auprc_ood_detector\n",
    "from ls_ood_detect.dimensionality_reduction import plot_samples_pacmap\n",
    "from ls_ood_detect.dimensionality_reduction import apply_pca_ds_split\n",
    "from ls_ood_detect.dimensionality_reduction import apply_pca_transform"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "data_path = \"./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/entropy/\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "cs_dlv3p_h_z_cs_normal_train_samples_np = np.load(data_path + 'cs_dlv3p_h_z_cs_normal_train_samples_np.npy')\n",
    "cs_dlv3p_h_z_cs_normal_valid_samples_np = np.load(data_path + 'cs_dlv3p_h_z_cs_normal_valid_samples_np.npy')\n",
    "cs_dlv3p_h_z_cs_normal_test_samples_np = np.load(data_path + 'cs_dlv3p_h_z_cs_normal_test_samples_np.npy')\n",
    "\n",
    "cs_dlv3p_h_z_cs_anomal_valid_samples_np = np.load(data_path + 'cs_dlv3p_h_z_cs_anomal_valid_samples_np.npy')\n",
    "cs_dlv3p_h_z_cs_anomal_test_samples_np = np.load(data_path + 'cs_dlv3p_h_z_cs_anomal_test_samples_np.npy')\n",
    "\n",
    "cs_dlv3p_h_z_ws_256512_valid_samples_np = np.load(data_path + 'cs_dlv3p_h_z_ws_256512_valid_samples_np.npy')\n",
    "cs_dlv3p_h_z_ws_256512_test_samples_np = np.load(data_path + 'cs_dlv3p_h_z_ws_256512_test_samples_np.npy')\n",
    "\n",
    "cs_dlv3p_h_z_ws_soil_256512_valid_samples_np = np.load(data_path + 'cs_dlv3p_h_z_ws_soil_256512_valid_samples_np.npy')\n",
    "cs_dlv3p_h_z_ws_soil_256512_test_samples_np = np.load(data_path + 'cs_dlv3p_h_z_ws_soil_256512_test_samples_np.npy')"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Deeplabv3+ Cityscapes LaRED Distribution Shift Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "ic(cs_dlv3p_h_z_cs_normal_train_samples_np.shape);\n",
    "ic(cs_dlv3p_h_z_cs_normal_valid_samples_np.shape);\n",
    "ic(cs_dlv3p_h_z_cs_normal_test_samples_np.shape);\n",
    "\n",
    "ic(cs_dlv3p_h_z_cs_anomal_valid_samples_np.shape);\n",
    "ic(cs_dlv3p_h_z_cs_anomal_test_samples_np.shape);\n",
    "\n",
    "ic(cs_dlv3p_h_z_ws_256512_valid_samples_np.shape);\n",
    "ic(cs_dlv3p_h_z_ws_256512_test_samples_np.shape);\n",
    "\n",
    "ic(cs_dlv3p_h_z_ws_soil_256512_valid_samples_np.shape);\n",
    "ic(cs_dlv3p_h_z_ws_soil_256512_test_samples_np.shape);"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "pca_cs_dlv3p_h_z_cs_normal_train_samples_np, pca_tr = apply_pca_ds_split(samples=cs_dlv3p_h_z_cs_normal_train_samples_np,\n",
    "                                                                         nro_components=58)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "pca_cs_dlv3p_h_z_cs_normal_valid_samples_np = apply_pca_transform(cs_dlv3p_h_z_cs_normal_valid_samples_np, pca_tr) # InD\n",
    "pca_cs_dlv3p_h_z_cs_normal_test_samples_np = apply_pca_transform(cs_dlv3p_h_z_cs_normal_test_samples_np, pca_tr) # InD\n",
    "\n",
    "pca_cs_dlv3p_h_z_cs_anomal_valid_samples_np= apply_pca_transform(cs_dlv3p_h_z_cs_anomal_valid_samples_np, pca_tr) # OoD | Anomaly\n",
    "pca_cs_dlv3p_h_z_cs_anomal_test_samples_np = apply_pca_transform(cs_dlv3p_h_z_cs_anomal_test_samples_np, pca_tr) # OoD | Anomaly\n",
    "\n",
    "pca_cs_dlv3p_h_z_ws_256512_valid_samples_np = apply_pca_transform(cs_dlv3p_h_z_ws_256512_valid_samples_np, pca_tr) # OoD | Anomaly\n",
    "pca_cs_dlv3p_h_z_ws_256512_test_samples_np = apply_pca_transform(cs_dlv3p_h_z_ws_256512_test_samples_np, pca_tr) # OoD | Anomaly\n",
    "\n",
    "pca_cs_dlv3p_h_z_ws_soil_256512_valid_samples_np = apply_pca_transform(cs_dlv3p_h_z_ws_soil_256512_valid_samples_np, pca_tr) # OoD | Anomaly\n",
    "pca_cs_dlv3p_h_z_ws_soil_256512_test_samples_np = apply_pca_transform(cs_dlv3p_h_z_ws_soil_256512_test_samples_np, pca_tr) # OoD | Anomaly"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "ic(pca_cs_dlv3p_h_z_cs_normal_train_samples_np.shape);\n",
    "ic(pca_cs_dlv3p_h_z_cs_normal_valid_samples_np.shape);\n",
    "ic(pca_cs_dlv3p_h_z_cs_normal_test_samples_np.shape);\n",
    "\n",
    "ic(pca_cs_dlv3p_h_z_cs_anomal_valid_samples_np.shape);\n",
    "ic(pca_cs_dlv3p_h_z_cs_anomal_test_samples_np.shape);\n",
    "\n",
    "ic(pca_cs_dlv3p_h_z_ws_256512_valid_samples_np.shape);\n",
    "ic(pca_cs_dlv3p_h_z_ws_256512_test_samples_np.shape);\n",
    "\n",
    "ic(pca_cs_dlv3p_h_z_ws_soil_256512_valid_samples_np.shape);\n",
    "ic(pca_cs_dlv3p_h_z_ws_soil_256512_test_samples_np.shape);"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "cs_dlv3p_ds_shift_detector = DetectorKDE(train_embeddings=pca_cs_dlv3p_h_z_cs_normal_train_samples_np)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "scores_pca_cs_dlv3p_h_z_cs_normal_valid_samples_np = get_hz_scores(cs_dlv3p_ds_shift_detector,\n",
    "                                                                  pca_cs_dlv3p_h_z_cs_normal_valid_samples_np)\n",
    "\n",
    "scores_pca_cs_dlv3p_h_z_cs_normal_test_samples_np = get_hz_scores(cs_dlv3p_ds_shift_detector,\n",
    "                                                                  pca_cs_dlv3p_h_z_cs_normal_test_samples_np)\n",
    "\n",
    "\n",
    "scores_pca_cs_dlv3p_h_z_cs_anomal_valid_samples_np = get_hz_scores(cs_dlv3p_ds_shift_detector,\n",
    "                                                                   pca_cs_dlv3p_h_z_cs_anomal_valid_samples_np)\n",
    "\n",
    "scores_pca_cs_dlv3p_h_z_cs_anomal_test_samples_np = get_hz_scores(cs_dlv3p_ds_shift_detector,\n",
    "                                                                  pca_cs_dlv3p_h_z_cs_anomal_test_samples_np)\n",
    "\n",
    "\n",
    "scores_pca_cs_dlv3p_h_z_ws_256512_valid_samples_np = get_hz_scores(cs_dlv3p_ds_shift_detector,\n",
    "                                                                   pca_cs_dlv3p_h_z_ws_256512_valid_samples_np)\n",
    "\n",
    "scores_pca_cs_dlv3p_h_z_ws_256512_test_samples_np = get_hz_scores(cs_dlv3p_ds_shift_detector,\n",
    "                                                                  pca_cs_dlv3p_h_z_ws_256512_test_samples_np)\n",
    "\n",
    "\n",
    "scores_pca_cs_dlv3p_h_z_ws_soil_256512_valid_samples_np = get_hz_scores(cs_dlv3p_ds_shift_detector,\n",
    "                                                                        pca_cs_dlv3p_h_z_ws_soil_256512_valid_samples_np)\n",
    "\n",
    "scores_pca_cs_dlv3p_h_z_ws_soil_256512_test_samples_np = get_hz_scores(cs_dlv3p_ds_shift_detector,\n",
    "                                                                       pca_cs_dlv3p_h_z_ws_soil_256512_test_samples_np)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "scores_pca_cs_dlv3p_ind_cs_normal_h_z = np.concatenate((scores_pca_cs_dlv3p_h_z_cs_normal_valid_samples_np,\n",
    "                                                        scores_pca_cs_dlv3p_h_z_cs_normal_test_samples_np))\n",
    "\n",
    "scores_pca_cs_dlv3p_ood_cs_anomal_h_z = np.concatenate((scores_pca_cs_dlv3p_h_z_cs_anomal_valid_samples_np,\n",
    "                                                        scores_pca_cs_dlv3p_h_z_cs_anomal_test_samples_np))\n",
    "\n",
    "scores_pca_cs_dlv3p_ood_ws_h_z = np.concatenate((scores_pca_cs_dlv3p_h_z_ws_256512_valid_samples_np,\n",
    "                                                 scores_pca_cs_dlv3p_h_z_ws_256512_test_samples_np))\n",
    "\n",
    "scores_pca_cs_dlv3p_ood_ws_soil_h_z = np.concatenate((scores_pca_cs_dlv3p_h_z_ws_soil_256512_valid_samples_np,\n",
    "                                                      scores_pca_cs_dlv3p_h_z_ws_soil_256512_test_samples_np))\n",
    "\n",
    "ic(scores_pca_cs_dlv3p_ind_cs_normal_h_z.shape);\n",
    "ic(scores_pca_cs_dlv3p_ood_cs_anomal_h_z.shape);\n",
    "ic(scores_pca_cs_dlv3p_ood_ws_h_z.shape);\n",
    "ic(scores_pca_cs_dlv3p_ood_ws_soil_h_z.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "ic(scores_pca_cs_dlv3p_ind_cs_normal_h_z.shape);\n",
    "ic(scores_pca_cs_dlv3p_ood_cs_anomal_h_z.shape);\n",
    "\n",
    "results_ws_anomal = get_hz_detector_results(detect_exp_name=\"cityscapes vs. cityscapes-anomalies\",\n",
    "                                            ind_samples_scores=scores_pca_cs_dlv3p_ind_cs_normal_h_z,\n",
    "                                            ood_samples_scores=scores_pca_cs_dlv3p_ood_cs_anomal_h_z)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "source": [
    "ic(scores_pca_cs_dlv3p_ind_cs_normal_h_z.shape);\n",
    "ic(scores_pca_cs_dlv3p_ood_ws_h_z.shape);\n",
    "\n",
    "results_cs = get_hz_detector_results(detect_exp_name=\"cityscapes vs. woodscape\",\n",
    "                                     ind_samples_scores=scores_pca_cs_dlv3p_ind_cs_normal_h_z,\n",
    "                                     ood_samples_scores=scores_pca_cs_dlv3p_ood_ws_h_z)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "ic(scores_pca_cs_dlv3p_ind_cs_normal_h_z.shape);\n",
    "ic(scores_pca_cs_dlv3p_ood_ws_soil_h_z.shape);\n",
    "\n",
    "results_ws_soil = get_hz_detector_results(detect_exp_name=\"cityscapes vs. woodscape-soiling\",\n",
    "                                          ind_samples_scores=scores_pca_cs_dlv3p_ind_cs_normal_h_z,\n",
    "                                          ood_samples_scores=scores_pca_cs_dlv3p_ood_ws_soil_h_z)"
   ],
   "outputs": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "source": [
    "df_score_ind_ws_normal = pd.DataFrame(scores_pca_cs_dlv3p_ind_cs_normal_h_z, columns=[\"LaRED score\"])\n",
    "df_score_ood_ws_anomal = pd.DataFrame(scores_pca_cs_dlv3p_ood_cs_anomal_h_z, columns=[\"LaRED score\"])\n",
    "df_score_ood_cs = pd.DataFrame(scores_pca_cs_dlv3p_ood_ws_h_z, columns=[\"LaRED score\"])\n",
    "df_score_ood_ws_soil = pd.DataFrame(scores_pca_cs_dlv3p_ood_ws_soil_h_z, columns=[\"LaRED score\"])\n",
    "\n",
    "df_score_ind_ws_normal.insert(0, \"Dataset\", \"\")\n",
    "df_score_ind_ws_normal.loc[:, \"Dataset\"] = \"InD-cityscapes-normal\"\n",
    "\n",
    "df_score_ood_ws_anomal.insert(0, \"Dataset\", \"\")\n",
    "df_score_ood_ws_anomal.loc[:, \"Dataset\"] = \"cityscapes-anomalies\"\n",
    "\n",
    "df_score_ood_cs.insert(0, \"Dataset\", \"\")\n",
    "df_score_ood_cs.loc[:, \"Dataset\"] = \"woodscape\"\n",
    "\n",
    "df_score_ood_ws_soil.insert(0, \"Dataset\", \"\")\n",
    "df_score_ood_ws_soil.loc[:, \"Dataset\"] = \"woodscape-soiling\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "source": [
    "df_h_z_valid_scores = pd.concat([df_score_ind_ws_normal,\n",
    "                                 df_score_ood_ws_anomal]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_h_z_valid_scores, x=\"LaRED score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "source": [
    "df_h_z_valid_scores = pd.concat([df_score_ind_ws_normal,\n",
    "                                 df_score_ood_cs]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_h_z_valid_scores, x=\"LaRED score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "source": [
    "df_h_z_valid_scores = pd.concat([df_score_ind_ws_normal,\n",
    "                                 df_score_ood_ws_soil]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_h_z_valid_scores, x=\"LaRED score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the best results are obtained with 58 PCA components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "source": [
    "data_path = \"./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-cityscapes/embeddings/cityscapes/entropy/\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "source": [
    "cs_dlv3p_h_z_cs_normal_train_samples_np = np.load(data_path + 'cs_dlv3p_h_z_cs_normal_train_samples_np.npy')\n",
    "cs_dlv3p_h_z_cs_normal_valid_samples_np = np.load(data_path + 'cs_dlv3p_h_z_cs_normal_valid_samples_np.npy')\n",
    "cs_dlv3p_h_z_cs_normal_test_samples_np = np.load(data_path + 'cs_dlv3p_h_z_cs_normal_test_samples_np.npy')\n",
    "\n",
    "cs_dlv3p_h_z_cs_anomal_valid_samples_np = np.load(data_path + 'cs_dlv3p_h_z_cs_anomal_valid_samples_np.npy')\n",
    "cs_dlv3p_h_z_cs_anomal_test_samples_np = np.load(data_path + 'cs_dlv3p_h_z_cs_anomal_test_samples_np.npy')\n",
    "\n",
    "cs_dlv3p_h_z_ws_256512_valid_samples_np = np.load(data_path + 'cs_dlv3p_h_z_ws_256512_valid_samples_np.npy')\n",
    "cs_dlv3p_h_z_ws_256512_test_samples_np = np.load(data_path + 'cs_dlv3p_h_z_ws_256512_test_samples_np.npy')\n",
    "\n",
    "cs_dlv3p_h_z_ws_soil_256512_valid_samples_np = np.load(data_path + 'cs_dlv3p_h_z_ws_soil_256512_valid_samples_np.npy')\n",
    "cs_dlv3p_h_z_ws_soil_256512_test_samples_np = np.load(data_path + 'cs_dlv3p_h_z_ws_soil_256512_test_samples_np.npy')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Deeplabv3+-Cityscapes LaREM Distribution Shift Detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "source": [
    "ic(cs_dlv3p_h_z_cs_normal_train_samples_np.shape);\n",
    "ic(cs_dlv3p_h_z_cs_normal_valid_samples_np.shape);\n",
    "ic(cs_dlv3p_h_z_cs_normal_test_samples_np.shape);\n",
    "\n",
    "ic(cs_dlv3p_h_z_cs_anomal_valid_samples_np.shape);\n",
    "ic(cs_dlv3p_h_z_cs_anomal_test_samples_np.shape);\n",
    "\n",
    "ic(cs_dlv3p_h_z_ws_256512_valid_samples_np.shape);\n",
    "ic(cs_dlv3p_h_z_ws_256512_test_samples_np.shape);\n",
    "\n",
    "ic(cs_dlv3p_h_z_ws_soil_256512_valid_samples_np.shape);\n",
    "ic(cs_dlv3p_h_z_ws_soil_256512_test_samples_np.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Detector LaREMd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "from sklearn.covariance import EmpiricalCovariance\n",
    "\n",
    "class LaREMPostprocessor:\n",
    "    def __init__(self,\n",
    "                 setup_flag: bool = False,\n",
    "                 get_2d_rep_mean: bool = False):\n",
    "\n",
    "        self.setup_flag = setup_flag\n",
    "        self.get_2d_rep_mean = get_2d_rep_mean\n",
    "        self.feats_mean = None\n",
    "        self.precision = None\n",
    "\n",
    "    def setup(self,\n",
    "              ind_feats: np.ndarray):\n",
    "        \n",
    "        if not self.setup_flag:\n",
    "            # estimate mean and variance from training set\n",
    "            print('\\n Estimating mean and variance from training set...')\n",
    "\n",
    "            self.feats_mean = ind_feats.mean(0)\n",
    "            self.feats_mean = np.mean(ind_feats, 0, keepdims=True)\n",
    "            \n",
    "            self.centered_data = ind_feats - self.feats_mean\n",
    "              \n",
    "            group_lasso = EmpiricalCovariance(assume_centered=False)\n",
    "            group_lasso.fit(self.centered_data)\n",
    "            \n",
    "            self.precision = group_lasso.precision_\n",
    "            \n",
    "            self.setup_flag = True\n",
    "            # we need to use:\n",
    "            # self.feats_mean & self.precision\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def postprocess(self,\n",
    "                    ood_feats: np.ndarray):\n",
    "           \n",
    "        diff = ood_feats - self.feats_mean\n",
    "        conf_score = -np.diag(np.matmul(np.matmul(diff, self.precision), np.transpose(diff)))\n",
    "\n",
    "        return conf_score"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "source": [
    "cs_dlv3p_larem_detector = LaREMPostprocessor()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "cs_dlv3p_larem_detector.setup(cs_dlv3p_h_z_cs_normal_train_samples_np)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "source": [
    "ic(cs_dlv3p_larem_detector.feats_mean.shape);\n",
    "ic(cs_dlv3p_larem_detector.precision.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "source": [
    "ind_cs_valid_larem_score = cs_dlv3p_larem_detector.postprocess(cs_dlv3p_h_z_cs_normal_valid_samples_np)\n",
    "ic(ind_cs_valid_larem_score.shape);\n",
    "ind_cs_test_larem_score = cs_dlv3p_larem_detector.postprocess(cs_dlv3p_h_z_cs_normal_test_samples_np)\n",
    "ic(ind_cs_test_larem_score.shape);\n",
    "\n",
    "\n",
    "ood_cs_anomal_valid_larem_score = cs_dlv3p_larem_detector.postprocess(cs_dlv3p_h_z_cs_anomal_valid_samples_np)\n",
    "ic(ood_cs_anomal_valid_larem_score.shape);\n",
    "ood_cs_anomal_test_larem_score = cs_dlv3p_larem_detector.postprocess(cs_dlv3p_h_z_cs_anomal_test_samples_np)\n",
    "ic(ood_cs_anomal_test_larem_score.shape);\n",
    "\n",
    "\n",
    "ood_ws_valid_larem_score = cs_dlv3p_larem_detector.postprocess(cs_dlv3p_h_z_ws_256512_valid_samples_np)\n",
    "ic(ood_ws_valid_larem_score.shape);\n",
    "ood_ws_test_larem_score = cs_dlv3p_larem_detector.postprocess(cs_dlv3p_h_z_ws_256512_test_samples_np)\n",
    "ic(ood_ws_test_larem_score.shape);\n",
    "\n",
    "\n",
    "ood_ws_soil_valid_larem_score = cs_dlv3p_larem_detector.postprocess(cs_dlv3p_h_z_ws_soil_256512_valid_samples_np)\n",
    "ic(ood_ws_soil_valid_larem_score.shape);\n",
    "ood_ws_soil_test_larem_score = cs_dlv3p_larem_detector.postprocess(cs_dlv3p_h_z_ws_soil_256512_test_samples_np)\n",
    "ic(ood_ws_soil_test_larem_score.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "source": [
    "cs_dlv3p_ind_cs_larem_scores = np.concatenate((ind_cs_valid_larem_score,\n",
    "                                                        ind_cs_test_larem_score))\n",
    "\n",
    "cs_dlv3p_ood_cs_anomal_larem_scores = np.concatenate((ood_cs_anomal_valid_larem_score,\n",
    "                                                      ood_cs_anomal_test_larem_score))\n",
    "\n",
    "cs_dlv3p_ood_ws_larem_scores = np.concatenate((ood_ws_valid_larem_score,\n",
    "                                               ood_ws_test_larem_score))\n",
    "\n",
    "cs_dlv3p_ood_ws_soil_larem_scores = np.concatenate((ood_ws_soil_valid_larem_score,\n",
    "                                                    ood_ws_soil_test_larem_score))\n",
    "\n",
    "ic(cs_dlv3p_ind_cs_larem_scores.shape);\n",
    "ic(cs_dlv3p_ood_cs_anomal_larem_scores.shape);\n",
    "ic(cs_dlv3p_ood_ws_larem_scores.shape);\n",
    "ic(cs_dlv3p_ood_ws_soil_larem_scores.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "source": [
    "ic(cs_dlv3p_ind_cs_larem_scores.shape);\n",
    "ic(cs_dlv3p_ood_cs_anomal_larem_scores.shape);\n",
    "\n",
    "results_ws_anomal = get_hz_detector_results(detect_exp_name=\"cityscapes vs. cityscapes-anomalies\",\n",
    "                                            ind_samples_scores=cs_dlv3p_ind_cs_larem_scores,\n",
    "                                            ood_samples_scores=cs_dlv3p_ood_cs_anomal_larem_scores)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "ic(cs_dlv3p_ind_cs_larem_scores.shape);\n",
    "ic(cs_dlv3p_ood_ws_larem_scores.shape);\n",
    "\n",
    "results_cs = get_hz_detector_results(detect_exp_name=\"cityscapes vs. woodscape\",\n",
    "                                     ind_samples_scores=cs_dlv3p_ind_cs_larem_scores,\n",
    "                                     ood_samples_scores=cs_dlv3p_ood_ws_larem_scores)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "source": [
    "ic(cs_dlv3p_ind_cs_larem_scores.shape);\n",
    "ic(cs_dlv3p_ood_ws_soil_larem_scores.shape);\n",
    "\n",
    "results_ws_soil = get_hz_detector_results(detect_exp_name=\"cityscapes vs. woodscape-soiling\",\n",
    "                                          ind_samples_scores=cs_dlv3p_ind_cs_larem_scores,\n",
    "                                          ood_samples_scores=cs_dlv3p_ood_ws_soil_larem_scores)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "source": [
    "df_score_ind_cs_normal = pd.DataFrame(cs_dlv3p_ind_cs_larem_scores, columns=[\"LaREM score\"])\n",
    "df_score_ood_cs_anomal = pd.DataFrame(cs_dlv3p_ood_cs_anomal_larem_scores, columns=[\"LaREM score\"])\n",
    "df_score_ood_ws = pd.DataFrame(cs_dlv3p_ood_ws_larem_scores, columns=[\"LaREM score\"])\n",
    "df_score_ood_ws_soil = pd.DataFrame(cs_dlv3p_ood_ws_soil_larem_scores, columns=[\"LaREM score\"])\n",
    "\n",
    "df_score_ind_cs_normal.insert(0, \"Dataset\", \"\")\n",
    "df_score_ind_cs_normal.loc[:, \"Dataset\"] = \"InD-cityscapes-normal\"\n",
    "\n",
    "df_score_ood_cs_anomal.insert(0, \"Dataset\", \"\")\n",
    "df_score_ood_cs_anomal.loc[:, \"Dataset\"] = \"cityscapes-anomalies\"\n",
    "\n",
    "df_score_ood_ws.insert(0, \"Dataset\", \"\")\n",
    "df_score_ood_ws.loc[:, \"Dataset\"] = \"woodscape\"\n",
    "\n",
    "df_score_ood_ws_soil.insert(0, \"Dataset\", \"\")\n",
    "df_score_ood_ws_soil.loc[:, \"Dataset\"] = \"woodscape-soiling\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "source": [
    "df_larem_scores = pd.concat([df_score_ind_cs_normal,\n",
    "                             df_score_ood_cs_anomal]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_larem_scores, x=\"LaREM score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "source": [
    "df_larem_scores = pd.concat([df_score_ind_cs_normal,\n",
    "                             df_score_ood_ws]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_larem_scores, x=\"LaREM score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "source": [
    "df_larem_scores = pd.concat([df_score_ind_cs_normal,\n",
    "                             df_score_ood_ws_soil]).reset_index(drop=True)\n",
    "\n",
    "sns.displot(df_larem_scores, x=\"LaREM score\", hue=\"Dataset\", kind=\"hist\", fill=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Shifted Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "source": [
    "dataset_path = './Data/DATASETS/CityScapes'\n",
    "batch_size = 1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "source": [
    "cs_dm_normal_dlv3p = CityscapesDataModule(data_dir=dataset_path,\n",
    "                                          batch_size=batch_size,\n",
    "                                          target_type='semantic',\n",
    "                                          img_size=(256, 512),\n",
    "                                          num_workers=10,\n",
    "                                          drop_last=True,\n",
    "                                          default_transforms=False, # Here this should be True!\n",
    "                                          default_img_mask_transforms=True) # And here this should be False!"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "source": [
    "cs_dlv3p_train_loader = cs_dm_normal_dlv3p.train_dataloader()\n",
    "cs_dlv3p_valid_loader = cs_dm_normal_dlv3p.val_dataloader()\n",
    "cs_dlv3p_test_loader = cs_dm_normal_dlv3p.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "source": [
    "dataiter_cs_valid = iter(cs_dlv3p_valid_loader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "source": [
    "batch_cs_data, batch_cs_labels = dataiter_cs_valid.next()\n",
    "plt.figure()\n",
    "show_dataset_image(batch_cs_data[0], cs_dm_normal_dlv3p.norm_mean, cs_dm_normal_dlv3p.norm_std)\n",
    "plt.figure()\n",
    "show_dataset_mask(batch_cs_labels[0].squeeze(), cs_dlv3p_train_loader.dataset.decode_target)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woodscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "source": [
    "ws_dataset_path = './Data/DATASETS/WoodScape/'\n",
    "batch_size = 1\n",
    "\n",
    "cmap = {0: [0, 0, 0],  # \"void\"\n",
    "        1: [128, 64, 128],  # \"road\",\n",
    "        2: [69, 76, 11],  # \"lanemarks\",\n",
    "        3: [0, 255, 0],  # \"curb\",\n",
    "        4: [220, 20, 60],  # \"person\",\n",
    "        5: [255, 0, 0],  # \"rider\",\n",
    "        6: [0, 0, 142],  # \"vehicles\",\n",
    "        7: [119, 11, 32],  # \"bicycle\",\n",
    "        8: [0, 0, 230],  # \"motorcycle\",\n",
    "        9: [220, 220, 0]  # \"traffic_sign\",\n",
    "        }\n",
    "\n",
    "# same values as in VainF Repository! - Probably not the best Values for Woodscapes!\n",
    "ws_dlv3p_norm_mean = [0.485, 0.456, 0.406]\n",
    "ws_dlv3p_norm_std = [0.229, 0.224, 0.225]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "source": [
    "ws_dm_normal_dlv3p_256_512 = WoodScapeDataModule(dataset_dir=ws_dataset_path,\n",
    "                                         img_size=(256, 512),\n",
    "                                         batch_size=batch_size,\n",
    "                                         default_transforms=True,\n",
    "                                         label_colours=cmap,\n",
    "                                         norm_mean=ws_dlv3p_norm_mean,\n",
    "                                         norm_std=ws_dlv3p_norm_std,\n",
    "                                         seed=9290,\n",
    "                                         drop_last=True)\n",
    "ws_dm_normal_dlv3p_256_512.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "source": [
    "ws_256512_dlv3p_valid_loader = ws_dm_normal_dlv3p_256_512.val_dataloader()\n",
    "ws_256512_dlv3p_test_loader = ws_dm_normal_dlv3p_256_512.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "source": [
    "dataiter_ws_valid = iter(ws_256512_dlv3p_valid_loader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "source": [
    "batch_ws_data, batch_ws_labels = dataiter_ws_valid.next()\n",
    "plt.figure()\n",
    "show_dataset_image(batch_ws_data[0], ws_dm_normal_dlv3p_256_512.norm_mean, ws_dm_normal_dlv3p_256_512.norm_std)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woodscape Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "source": [
    "ws_dlv3p_anomaly_valid_loader = ws_dm_normal_dlv3p_256_512.anomaly_val_dataloader()\n",
    "ws_dlv3p_anomaly_test_loader = ws_dm_normal_dlv3p_256_512.anomaly_test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "source": [
    "dataiter_ws_anomal_valid = iter(ws_dlv3p_anomaly_valid_loader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "source": [
    "batch_ws_anomal_data, batch_ws_anomal_labels = dataiter_ws_anomal_valid.next()\n",
    "plt.figure()\n",
    "show_dataset_image(batch_ws_anomal_data[0], ws_dm_normal_dlv3p_256_512.norm_mean, ws_dm_normal_dlv3p_256_512.norm_std)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woodscape-Soiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "source": [
    "woodscape_soil_256512_dm = WoodScapeSoilingDataModule(dataset_dir=\"./Data/DATASETS/WoodScape/soiling_dataset/\",\n",
    "                                                      img_size=(256, 512),\n",
    "                                                      batch_size=1,\n",
    "                                                      default_transforms=True,\n",
    "                                                      seed=9290)\n",
    "woodscape_soil_256512_dm.setup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "source": [
    "ws_soiling_256512_valid_loader = woodscape_soil_256512_dm.val_dataloader()\n",
    "ws_soiling_256512_test_loader = woodscape_soil_256512_dm.test_dataloader()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "dataiter_ws_soiling_valid = iter(ws_soiling_256512_valid_loader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "source": [
    "batch_ws_soil_data, batch_ws_soil_labels = dataiter_ws_soiling_valid.next()\n",
    "plt.figure()\n",
    "show_dataset_image(batch_ws_soil_data[0], ws_dm_normal_dlv3p_256_512.norm_mean, ws_dm_normal_dlv3p_256_512.norm_std)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "source": [
    "batch_ws_soil_data.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeplabv3+ Cityscapes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "source": [
    "cs_dlv3p_path = \"./lightning_logs/version_158692/checkpoints/epoch=403-step=18584.ckpt\"\n",
    "cs_dlv3p_model = DeepLabV3PlusModule.load_from_checkpoint(checkpoint_path=cs_dlv3p_path)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "source": [
    "ic(cs_dlv3p_model.pred_loss_type);\n",
    "ic(cs_dlv3p_model.n_class);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "source": [
    "cs_dlv3p_model.eval();"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeplabv3+ Woodscape Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "ws_dlv3p_path = \"./Data/EXPERIMENTS/CVPR-2024/semantic_segmentation/deeplabv3p-woodscape/models/version_66126/checkpoints/last.ckpt\"\n",
    "ws_dlv3p_model = DeepLabV3PlusModule.load_from_checkpoint(checkpoint_path=ws_dlv3p_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "ic(ws_dlv3p_model.pred_loss_type);\n",
    "ic(ws_dlv3p_model.n_class);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "ws_dlv3p_model.eval();"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "ic(ws_dlv3p_model.deeplab_v3plus_model.drop_block1);\n",
    "ic(ws_dlv3p_model.deeplab_v3plus_model.drop_block1.block_size);\n",
    "ic(ws_dlv3p_model.deeplab_v3plus_model.drop_block1.drop_prob);\n",
    "ic(ws_dlv3p_model.deeplab_v3plus_model.drop_block1.training);"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "source": [
    "ic(cs_dlv3p_model.deeplab_v3plus_model.drop_block1);\n",
    "ic(cs_dlv3p_model.deeplab_v3plus_model.drop_block1.block_size);\n",
    "ic(cs_dlv3p_model.deeplab_v3plus_model.drop_block1.drop_prob);\n",
    "ic(cs_dlv3p_model.deeplab_v3plus_model.drop_block1.training);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "source": [
    "cs_dlv3p_model.deeplab_v3plus_model.backbone.layer4[2]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "source": [
    "cs_dlv3p_model.deeplab_v3plus_model.backbone.layer4[2].relu"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "cs_dlv3p_hook_resnet_output = Hook(cs_dlv3p_model.deeplab_v3plus_model.backbone.layer4[2])\n",
    "cs_dlv3p_hook_resnet_output"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "source": [
    "from dropblock import DropBlock2D\n",
    "\n",
    "class MCSamplerModule(nn.Module):\n",
    "    \"\"\"LeNet Neural Network Architecture\n",
    "    Author: Andrei Bursuc\n",
    "    https://github.com/abursuc/dldiy-gtsrb\n",
    "    \"\"\"\n",
    "    def __init__(self, mc_samples=8, get_2d_rep_mean: bool = True):\n",
    "\n",
    "        super(MCSamplerModule, self).__init__()\n",
    "        \n",
    "        self.get_2d_rep_mean = get_2d_rep_mean\n",
    "        self.mc_samples = mc_samples\n",
    "        # self.samples = []\n",
    "        \n",
    "        self.drop_blocks = nn.ModuleList([DropBlock2D(block_size=8, drop_prob=0.5) for i in range (self.mc_samples)])\n",
    "\n",
    "    def forward(self, latent_rep):\n",
    "        samples = []        \n",
    "        for i, l in enumerate(self.drop_blocks):\n",
    "            mc_sample = self.drop_blocks[i](latent_rep)\n",
    "                        \n",
    "            if self.get_2d_rep_mean:\n",
    "                # Get image HxW mean:\n",
    "                mc_sample = torch.mean(mc_sample, dim=2, keepdim=True)\n",
    "                mc_sample = torch.mean(mc_sample, dim=3, keepdim=True)\n",
    "                # Remove useless dimensions:\n",
    "                mc_sample = torch.squeeze(mc_sample, dim=2)\n",
    "                mc_sample = torch.squeeze(mc_sample, dim=2)\n",
    "                \n",
    "            # self.samples.append(mc_sample)\n",
    "            samples.append(mc_sample)\n",
    "        # self.samples_t = torch.cat(self.samples)\n",
    "        self.samples_t = torch.cat(samples)\n",
    "        return self.samples_t"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "source": [
    "my_mc_sampler =  MCSamplerModule(mc_samples=16)\n",
    "my_mc_sampler.drop_blocks\n",
    "my_mc_sampler.train()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "source": [
    "my_mc_sampler.drop_blocks[10].training"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LaREM Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "source": [
    "from time import monotonic\n",
    "    \n",
    "def record_time(function):\n",
    "    def wrap(*args, **kwargs):\n",
    "        start_time = monotonic()\n",
    "        function_return = function(*args, **kwargs)\n",
    "        delta_t = monotonic() - start_time\n",
    "        # print(f\"Run time {monotonic() - start_time} seconds\")\n",
    "        # print(f\"Run time {delta_t} seconds\")\n",
    "        return function_return, delta_t\n",
    "    return wrap"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "source": [
    "class LaRExMonitor:\n",
    "    def __init__(self,\n",
    "                 dnn_model: nn.Module,\n",
    "                 larem_detector,\n",
    "                 mcd_samples_nro=16,\n",
    "                 get_2d_rep_mean=True):\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.dnn_model = dnn_model\n",
    "        self.dnn_model.to(self.device)\n",
    "        \n",
    "        self.mcd_samples_nro = mcd_samples_nro\n",
    "        self.get_2d_rep_mean = get_2d_rep_mean\n",
    "        self.larem_detector = larem_detector\n",
    "        \n",
    "        self.mc_sampler =  MCSamplerModule(mc_samples=self.mcd_samples_nro, get_2d_rep_mean=get_2d_rep_mean)\n",
    "        self.mc_sampler.to(self.device)\n",
    "        self.mc_sampler.train()\n",
    "        \n",
    "        self.sample_larex_score = None\n",
    "\n",
    "    @record_time\n",
    "    def get_larex_score(self,\n",
    "                        input_image,\n",
    "                        layer_hook):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_image = input_image.to(self.device)\n",
    "            pred_logits = self.dnn_model(input_image)\n",
    "            latent_rep = layer_hook.output  # latent representation sample\n",
    "    \n",
    "        mc_samples_t = self.mc_sampler(latent_rep)\n",
    "        _, sample_h_z = get_dl_h_z(mc_samples_t, self.mcd_samples_nro)        \n",
    "        self.sample_larex_score = self.larem_detector.postprocess(sample_h_z)\n",
    "        return self.sample_larex_score\n",
    "    \n",
    "    @record_time\n",
    "    def get_layer_mc_samples(self,\n",
    "                             input_image,\n",
    "                             layer_hook):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_image = input_image.to(self.device)\n",
    "            pred_logits = self.dnn_model(input_image)\n",
    "            latent_rep = layer_hook.output  # latent representation sample\n",
    "    \n",
    "        mc_samples_t = self.mc_sampler(latent_rep)\n",
    "        return mc_samples_t    \n",
    "    \n",
    "    @record_time\n",
    "    def get_mc_samples(self,\n",
    "                       input_image,\n",
    "                       layer_hook):\n",
    "        mc_samples = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(self.mcd_samples_nro):\n",
    "                input_image = input_image.to(self.device)\n",
    "                pred_logits = self.dnn_model(input_image)\n",
    "                latent_rep = layer_hook.output    \n",
    "                mc_samples.append(pred_logits)\n",
    "            \n",
    "            mc_samples_t = torch.cat(mc_samples)\n",
    "            mc_samples_np = mc_samples_t.cpu().numpy()\n",
    "        return mc_samples_np"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "source": [
    "cs_dplbv3p_larem_monitor = LaRExMonitor(dnn_model=cs_dlv3p_model.deeplab_v3plus_model,\n",
    "                                        larem_detector=cs_dlv3p_larem_detector,\n",
    "                                        mcd_samples_nro=16,\n",
    "                                        get_2d_rep_mean=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "source": [
    "print(cs_dplbv3p_larem_monitor.device)\n",
    "print(cs_dplbv3p_larem_monitor.device)\n",
    "print(cs_dplbv3p_larem_monitor.mc_sampler.get_2d_rep_mean)\n",
    "print(cs_dplbv3p_larem_monitor.mc_sampler.drop_blocks[10].training)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "source": [
    "ic(batch_cs_data.shape);\n",
    "ic(batch_ws_data.shape);\n",
    "ic(batch_ws_soil_data.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "source": [
    "cs_image_score, delta_t1 = cs_dplbv3p_larem_monitor.get_larex_score(input_image=batch_cs_data,\n",
    "                                                                        layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "\n",
    "ws_image_score, delta_t2 = cs_dplbv3p_larem_monitor.get_larex_score(input_image=batch_ws_data,\n",
    "                                                                    layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "\n",
    "ws_soil_image_score, delta_t3 = cs_dplbv3p_larem_monitor.get_larex_score(input_image=batch_ws_soil_data,\n",
    "                                                                         layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Cityscapes sample LaREM score: {}  -  time: {}\". format(cs_image_score, delta_t1))\n",
    "print(\"Woodscape sample LaREM score: {}  -  time: {}\".format( ws_image_score, delta_t2))\n",
    "print(\"Woodscape-Soiling sample LaREM score: {}  -  time: {}\".format(ws_soil_image_score, delta_t3))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "cs_image_score = cs_dplbv3p_larem_monitor.get_layer_mc_samples(input_image=batch_cs_data,\n",
    "                                                               layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "\n",
    "ws_image_score = cs_dplbv3p_larem_monitor.get_layer_mc_samples(input_image=batch_ws_data,\n",
    "                                                               layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "\n",
    "ws_soil_image_score = cs_dplbv3p_larem_monitor.get_layer_mc_samples(input_image=batch_ws_soil_data,\n",
    "                                                                    layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Cityscapes samples shape: \", cs_image_score.shape)\n",
    "print(\"Woodscape sample shape: \", ws_image_score.shape)\n",
    "print(\"Woodscape-Soiling sample shape: \", ws_soil_image_score.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "source": [
    "cs_image_samples = cs_dplbv3p_larem_monitor.get_mc_samples(input_image=batch_cs_data,\n",
    "                                                          layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "\n",
    "ws_image_samples = cs_dplbv3p_larem_monitor.get_mc_samples(input_image=batch_ws_data,\n",
    "                                                          layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "\n",
    "ws_soil_image_samples = cs_dplbv3p_larem_monitor.get_mc_samples(input_image=batch_ws_soil_data,\n",
    "                                                               layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Cityscapes samples shape: \", cs_image_samples.shape)\n",
    "print(\"Woodscape sample shape: \", ws_image_samples.shape)\n",
    "print(\"Woodscape-Soiling sample shape: \", ws_soil_image_samples.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "source": [
    "timing_cs = []\n",
    "timing_ws = []\n",
    "timing_ws_soil = []\n",
    "\n",
    "for i in range(100):\n",
    "    cs_image_score, delta_t1 = cs_dplbv3p_larem_monitor.get_larex_score(input_image=batch_cs_data,\n",
    "                                                                        layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    timing_cs.append(delta_t1)\n",
    "    \n",
    "timing_cs_np = np.asarray(timing_cs)\n",
    "mean_time_cs_np = np.mean(timing_cs_np)\n",
    "std_time_cs_np = np.std(timing_cs_np)\n",
    "    \n",
    "for i in range(100):\n",
    "    ws_image_score, delta_t2 = cs_dplbv3p_larem_monitor.get_larex_score(input_image=batch_ws_data,\n",
    "                                                                        layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    \n",
    "    timing_ws.append(delta_t2)\n",
    "    \n",
    "timing_ws_np = np.asarray(timing_ws)\n",
    "mean_time_ws_np = np.mean(timing_ws_np)\n",
    "std_time_ws_np = np.std(timing_ws_np)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    ws_soil_image_score, delta_t3 = cs_dplbv3p_larem_monitor.get_larex_score(input_image=batch_ws_soil_data,\n",
    "                                                                             layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    \n",
    "    timing_ws_soil.append(delta_t3)\n",
    "    \n",
    "timing_ws_soil_np = np.asarray(timing_ws_soil)\n",
    "mean_time_ws_soil_np = np.mean(timing_ws_soil_np)\n",
    "std_time_ws_soil_np = np.std(timing_ws_soil_np)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Cityscapes sample LaREM score time: {} +/- {}\".format(mean_time_cs_np, std_time_cs_np))\n",
    "print(\"Woodscape sample LaREM score time: {} +/- {}\".format( mean_time_ws_np, std_time_ws_np))\n",
    "print(\"Woodscape-Soiling sample LaREM score time: {} +/- {}\".format(mean_time_ws_soil_np, std_time_ws_soil_np))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "source": [
    "timing_cs = []\n",
    "timing_ws = []\n",
    "timing_ws_soil = []\n",
    "\n",
    "for i in range(100):\n",
    "    cs_image_score, delta_t1 = cs_dplbv3p_larem_monitor.get_larex_score(input_image=batch_cs_data,\n",
    "                                                                        layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    timing_cs.append(delta_t1)\n",
    "    \n",
    "timing_cs_np = np.asarray(timing_cs)\n",
    "mean_time_cs_np = np.mean(timing_cs_np)\n",
    "std_time_cs_np = np.std(timing_cs_np)\n",
    "    \n",
    "for i in range(100):\n",
    "    ws_image_score, delta_t2 = cs_dplbv3p_larem_monitor.get_larex_score(input_image=batch_ws_data,\n",
    "                                                                        layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    \n",
    "    timing_ws.append(delta_t2)\n",
    "    \n",
    "timing_ws_np = np.asarray(timing_ws)\n",
    "mean_time_ws_np = np.mean(timing_ws_np)\n",
    "std_time_ws_np = np.std(timing_ws_np)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    ws_soil_image_score, delta_t3 = cs_dplbv3p_larem_monitor.get_larex_score(input_image=batch_ws_soil_data,\n",
    "                                                                             layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    \n",
    "    timing_ws_soil.append(delta_t3)\n",
    "    \n",
    "timing_ws_soil_np = np.asarray(timing_ws_soil)\n",
    "mean_time_ws_soil_np = np.mean(timing_ws_soil_np)\n",
    "std_time_ws_soil_np = np.std(timing_ws_soil_np)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Cityscapes sample LaREM score time: {} +/- {}\".format(mean_time_cs_np, std_time_cs_np))\n",
    "print(\"Woodscape sample LaREM score time: {} +/- {}\".format( mean_time_ws_np, std_time_ws_np))\n",
    "print(\"Woodscape-Soiling sample LaREM score time: {} +/- {}\".format(mean_time_ws_soil_np, std_time_ws_soil_np))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "source": [
    "timing_larem_score = []\n",
    "timing_layer_mc_samples = []\n",
    "timing_mc_samples = []\n",
    "\n",
    "for i in range(100):\n",
    "    cs_image_score, delta_t1 = cs_dplbv3p_larem_monitor.get_larex_score(input_image=batch_cs_data,\n",
    "                                                                        layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    timing_larem_score.append(delta_t1)\n",
    "    \n",
    "timing_larem_score_np = np.asarray(timing_larem_score)\n",
    "mean_time_larem_score_np = np.mean(timing_larem_score_np)\n",
    "std_time_larem_score_np = np.std(timing_larem_score_np)\n",
    "    \n",
    "for i in range(100):\n",
    "    cs_image_score, delta_t2 = cs_dplbv3p_larem_monitor.get_layer_mc_samples(input_image=batch_cs_data,\n",
    "                                                                             layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    \n",
    "    timing_layer_mc_samples.append(delta_t2)\n",
    "    \n",
    "timing_layer_mc_samples_np = np.asarray(timing_layer_mc_samples)\n",
    "mean_time_layer_mc_samples_np = np.mean(timing_layer_mc_samples_np)\n",
    "std_time_layer_mc_samples_np = np.std(timing_layer_mc_samples_np)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    cs_image_score, delta_t3 = cs_dplbv3p_larem_monitor.get_mc_samples(input_image=batch_cs_data,\n",
    "                                                                       layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    \n",
    "    timing_mc_samples.append(delta_t3)\n",
    "    \n",
    "timing_mc_samples_np = np.asarray(timing_mc_samples)\n",
    "mean_time_mc_samples_np = np.mean(timing_mc_samples_np)\n",
    "std_time_mc_samples_np = np.std(timing_mc_samples_np)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"LaREM score time: {} +/- {}\".format(mean_time_larem_score_np, std_time_larem_score_np))\n",
    "print(\"Layer MCD samples time: {} +/- {}\".format( mean_time_layer_mc_samples_np, std_time_layer_mc_samples_np))\n",
    "print(\"MCD samples time: {} +/- {}\".format(mean_time_mc_samples_np, std_time_mc_samples_np))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LaRED Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "source": [
    "from time import monotonic\n",
    "    \n",
    "def record_time(function):\n",
    "    def wrap(*args, **kwargs):\n",
    "        start_time = monotonic()\n",
    "        function_return = function(*args, **kwargs)\n",
    "        delta_t = monotonic() - start_time\n",
    "        # print(f\"Run time {monotonic() - start_time} seconds\")\n",
    "        # print(f\"Run time {delta_t} seconds\")\n",
    "        return function_return, delta_t\n",
    "    return wrap"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "source": [
    "class LaREDMonitor:\n",
    "    def __init__(self,\n",
    "                 dnn_model: nn.Module,\n",
    "                 lared_detector,\n",
    "                 pca_tr = None,\n",
    "                 mcd_samples_nro=16,\n",
    "                 get_2d_rep_mean=True):\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.dnn_model = dnn_model\n",
    "        self.dnn_model.to(self.device)\n",
    "        \n",
    "        self.mcd_samples_nro = mcd_samples_nro\n",
    "        self.get_2d_rep_mean = get_2d_rep_mean\n",
    "        self.pca_tr = pca_tr\n",
    "        self.lared_detector = lared_detector\n",
    "        \n",
    "        self.mc_sampler =  MCSamplerModule(mc_samples=self.mcd_samples_nro, get_2d_rep_mean=get_2d_rep_mean)\n",
    "        self.mc_sampler.to(self.device)\n",
    "        self.mc_sampler.train()\n",
    "        \n",
    "        self.sample_lared_score = None\n",
    "\n",
    "    @record_time\n",
    "    def get_lared_score(self,\n",
    "                        input_image,\n",
    "                        layer_hook):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_image = input_image.to(self.device)\n",
    "            pred_logits = self.dnn_model(input_image)\n",
    "            latent_rep = layer_hook.output  # latent representation sample\n",
    "    \n",
    "        mc_samples_t = self.mc_sampler(latent_rep)\n",
    "        _, sample_h_z = get_dl_h_z(mc_samples_t, self.mcd_samples_nro)\n",
    "        \n",
    "        if self.pca_tr:\n",
    "            sample_h_z = apply_pca_transform(sample_h_z, self.pca_tr)\n",
    "            \n",
    "        \n",
    "        self.sample_lared_score = get_hz_scores(self.lared_detector, sample_h_z)        \n",
    "        # self.sample_lared_score = self.lared_detector.postprocess(sample_h_z)\n",
    "        \n",
    "        \n",
    "        return self.sample_lared_score\n",
    "    \n",
    "    @record_time\n",
    "    def get_layer_mc_samples(self,\n",
    "                             input_image,\n",
    "                             layer_hook):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_image = input_image.to(self.device)\n",
    "            pred_logits = self.dnn_model(input_image)\n",
    "            latent_rep = layer_hook.output  # latent representation sample\n",
    "    \n",
    "        mc_samples_t = self.mc_sampler(latent_rep)\n",
    "        return mc_samples_t    \n",
    "    \n",
    "    @record_time\n",
    "    def get_mc_samples(self,\n",
    "                       input_image,\n",
    "                       layer_hook):\n",
    "        mc_samples = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(self.mcd_samples_nro):\n",
    "                input_image = input_image.to(self.device)\n",
    "                pred_logits = self.dnn_model(input_image)\n",
    "                latent_rep = layer_hook.output    \n",
    "                mc_samples.append(pred_logits)\n",
    "            \n",
    "            mc_samples_t = torch.cat(mc_samples)\n",
    "            mc_samples_np = mc_samples_t.cpu().numpy()\n",
    "        return mc_samples_np"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "source": [
    "cs_dplbv3p_lared_monitor = LaREDMonitor(dnn_model=cs_dlv3p_model.deeplab_v3plus_model,\n",
    "                                        pca_tr=pca_tr,\n",
    "                                        lared_detector=cs_dlv3p_ds_shift_detector,\n",
    "                                        mcd_samples_nro=16,\n",
    "                                        get_2d_rep_mean=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "source": [
    "print(cs_dplbv3p_larem_monitor.device)\n",
    "print(cs_dplbv3p_larem_monitor.device)\n",
    "print(cs_dplbv3p_larem_monitor.mc_sampler.get_2d_rep_mean)\n",
    "print(cs_dplbv3p_larem_monitor.mc_sampler.drop_blocks[10].training)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "source": [
    "ic(batch_cs_data.shape);\n",
    "ic(batch_ws_data.shape);\n",
    "ic(batch_ws_soil_data.shape);"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "source": [
    "timing_larem_score = []\n",
    "timing_layer_mc_samples = []\n",
    "timing_mc_samples = []\n",
    "\n",
    "for i in range(100):\n",
    "    cs_image_score, delta_t1 = cs_dplbv3p_lared_monitor.get_lared_score(input_image=batch_cs_data,\n",
    "                                                                        layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    timing_larem_score.append(delta_t1)\n",
    "    \n",
    "timing_larem_score_np = np.asarray(timing_larem_score)\n",
    "mean_time_larem_score_np = np.mean(timing_larem_score_np)\n",
    "std_time_larem_score_np = np.std(timing_larem_score_np)\n",
    "    \n",
    "for i in range(100):\n",
    "    cs_image_score, delta_t2 = cs_dplbv3p_lared_monitor.get_layer_mc_samples(input_image=batch_cs_data,\n",
    "                                                                             layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    \n",
    "    timing_layer_mc_samples.append(delta_t2)\n",
    "    \n",
    "timing_layer_mc_samples_np = np.asarray(timing_layer_mc_samples)\n",
    "mean_time_layer_mc_samples_np = np.mean(timing_layer_mc_samples_np)\n",
    "std_time_layer_mc_samples_np = np.std(timing_layer_mc_samples_np)\n",
    "\n",
    "\n",
    "# for i in range(100):\n",
    "#     cs_image_score, delta_t3 = cs_dplbv3p_larem_monitor.get_mc_samples(input_image=batch_cs_data,\n",
    "#                                                                        layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    \n",
    "#     timing_mc_samples.append(delta_t3)\n",
    "    \n",
    "# timing_mc_samples_np = np.asarray(timing_mc_samples)\n",
    "# mean_time_mc_samples_np = np.mean(timing_mc_samples_np)\n",
    "# std_time_mc_samples_np = np.std(timing_mc_samples_np)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"LaRED score time: {} +/- {}\".format(mean_time_larem_score_np, std_time_larem_score_np))\n",
    "print(\"Layer MCD samples time: {} +/- {}\".format( mean_time_layer_mc_samples_np, std_time_layer_mc_samples_np))\n",
    "# print(\"MCD samples time: {} +/- {}\".format(mean_time_mc_samples_np, std_time_mc_samples_np))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "source": [
    "timing_larem_score = []\n",
    "timing_layer_mc_samples = []\n",
    "timing_mc_samples = []\n",
    "\n",
    "for i in range(100):\n",
    "    cs_image_score, delta_t1 = cs_dplbv3p_lared_monitor.get_lared_score(input_image=batch_cs_data,\n",
    "                                                                        layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    timing_larem_score.append(delta_t1)\n",
    "    \n",
    "timing_larem_score_np = np.asarray(timing_larem_score)\n",
    "mean_time_larem_score_np = np.mean(timing_larem_score_np)\n",
    "std_time_larem_score_np = np.std(timing_larem_score_np)\n",
    "    \n",
    "for i in range(100):\n",
    "    cs_image_score, delta_t2 = cs_dplbv3p_lared_monitor.get_layer_mc_samples(input_image=batch_cs_data,\n",
    "                                                                             layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    \n",
    "    timing_layer_mc_samples.append(delta_t2)\n",
    "    \n",
    "timing_layer_mc_samples_np = np.asarray(timing_layer_mc_samples)\n",
    "mean_time_layer_mc_samples_np = np.mean(timing_layer_mc_samples_np)\n",
    "std_time_layer_mc_samples_np = np.std(timing_layer_mc_samples_np)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"LaRED score time: {} +/- {}\".format(mean_time_larem_score_np, std_time_larem_score_np))\n",
    "print(\"Layer MCD samples time: {} +/- {}\".format( mean_time_layer_mc_samples_np, std_time_layer_mc_samples_np))\n",
    "# print(\"MCD samples time: {} +/- {}\".format(mean_time_mc_samples_np, std_time_mc_samples_np))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "source": [
    "timing_larem_score = []\n",
    "timing_layer_mc_samples = []\n",
    "timing_mc_samples = []\n",
    "\n",
    "for i in range(100):\n",
    "    cs_image_score, delta_t1 = cs_dplbv3p_lared_monitor.get_lared_score(input_image=batch_cs_data,\n",
    "                                                                        layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    timing_larem_score.append(delta_t1)\n",
    "    \n",
    "timing_larem_score_np = np.asarray(timing_larem_score)\n",
    "mean_time_larem_score_np = np.mean(timing_larem_score_np)\n",
    "std_time_larem_score_np = np.std(timing_larem_score_np)\n",
    "    \n",
    "for i in range(100):\n",
    "    cs_image_score, delta_t2 = cs_dplbv3p_lared_monitor.get_layer_mc_samples(input_image=batch_cs_data,\n",
    "                                                                             layer_hook=cs_dlv3p_hook_resnet_output)\n",
    "    \n",
    "    timing_layer_mc_samples.append(delta_t2)\n",
    "    \n",
    "timing_layer_mc_samples_np = np.asarray(timing_layer_mc_samples)\n",
    "mean_time_layer_mc_samples_np = np.mean(timing_layer_mc_samples_np)\n",
    "std_time_layer_mc_samples_np = np.std(timing_layer_mc_samples_np)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"LaRED score time: {} +/- {}\".format(mean_time_larem_score_np, std_time_larem_score_np))\n",
    "print(\"Layer MCD samples time: {} +/- {}\".format( mean_time_layer_mc_samples_np, std_time_layer_mc_samples_np))\n",
    "# print(\"MCD samples time: {} +/- {}\".format(mean_time_mc_samples_np, std_time_mc_samples_np))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Semantic_Segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
